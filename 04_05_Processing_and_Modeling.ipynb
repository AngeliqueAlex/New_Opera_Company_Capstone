{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddb80c4b-3cf8-459b-b44e-f8bf5911030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de73d6eb-0f44-4958-bd4e-b102a5e698e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>iso</th>\n",
       "      <th>city</th>\n",
       "      <th>composer</th>\n",
       "      <th>db</th>\n",
       "      <th>dd</th>\n",
       "      <th>nat</th>\n",
       "      <th>mf</th>\n",
       "      <th>work</th>\n",
       "      <th>worknat</th>\n",
       "      <th>...</th>\n",
       "      <th>performances_season_by_city</th>\n",
       "      <th>perf_per_1k_ppl_city_pop</th>\n",
       "      <th>opera_by_composer</th>\n",
       "      <th>performances_season_by_country_total</th>\n",
       "      <th>performances_season_by_city_total</th>\n",
       "      <th>perf_total_per_1k_city_pop</th>\n",
       "      <th>perf_total_per_10k_co_pop</th>\n",
       "      <th>Season Year</th>\n",
       "      <th>country_change_from_previous_season</th>\n",
       "      <th>city_change_from_previous_season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1213</td>\n",
       "      <td>al</td>\n",
       "      <td>Tirana</td>\n",
       "      <td>Lortzing</td>\n",
       "      <td>1801</td>\n",
       "      <td>1851</td>\n",
       "      <td>de</td>\n",
       "      <td>m</td>\n",
       "      <td>Ali Pascha von Janina</td>\n",
       "      <td>de</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.021506</td>\n",
       "      <td>Ali Pascha von Janina by Lor</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>0.262847</td>\n",
       "      <td>0.385301</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1213</td>\n",
       "      <td>al</td>\n",
       "      <td>Tirana</td>\n",
       "      <td>Mozart</td>\n",
       "      <td>1756</td>\n",
       "      <td>1791</td>\n",
       "      <td>at</td>\n",
       "      <td>m</td>\n",
       "      <td>Don Giovanni</td>\n",
       "      <td>it</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.021506</td>\n",
       "      <td>Don Giovanni by Moz</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>0.262847</td>\n",
       "      <td>0.385301</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1213</td>\n",
       "      <td>al</td>\n",
       "      <td>Tirana</td>\n",
       "      <td>Puccini</td>\n",
       "      <td>1858</td>\n",
       "      <td>1924</td>\n",
       "      <td>it</td>\n",
       "      <td>m</td>\n",
       "      <td>Tosca</td>\n",
       "      <td>it</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.021506</td>\n",
       "      <td>Tosca by Puc</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>0.262847</td>\n",
       "      <td>0.385301</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1213</td>\n",
       "      <td>am</td>\n",
       "      <td>Yerevan</td>\n",
       "      <td>Spendiaryan</td>\n",
       "      <td>1871</td>\n",
       "      <td>1928</td>\n",
       "      <td>am</td>\n",
       "      <td>m</td>\n",
       "      <td>Almast</td>\n",
       "      <td>am</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004573</td>\n",
       "      <td>Almast by Spe</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>0.101510</td>\n",
       "      <td>0.371147</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1213</td>\n",
       "      <td>am</td>\n",
       "      <td>Yerevan</td>\n",
       "      <td>Tigranian</td>\n",
       "      <td>1879</td>\n",
       "      <td>1950</td>\n",
       "      <td>am</td>\n",
       "      <td>m</td>\n",
       "      <td>Anoush</td>\n",
       "      <td>am</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004573</td>\n",
       "      <td>Anoush by Tig</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>0.101510</td>\n",
       "      <td>0.371147</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   season iso     city     composer    db    dd nat mf                   work  \\\n",
       "0    1213  al   Tirana     Lortzing  1801  1851  de  m  Ali Pascha von Janina   \n",
       "1    1213  al   Tirana       Mozart  1756  1791  at  m           Don Giovanni   \n",
       "2    1213  al   Tirana      Puccini  1858  1924  it  m                  Tosca   \n",
       "3    1213  am  Yerevan  Spendiaryan  1871  1928  am  m                 Almast   \n",
       "4    1213  am  Yerevan    Tigranian  1879  1950  am  m                 Anoush   \n",
       "\n",
       "  worknat  ... performances_season_by_city perf_per_1k_ppl_city_pop  \\\n",
       "0      de  ...                           9                 0.021506   \n",
       "1      it  ...                           9                 0.021506   \n",
       "2      it  ...                           9                 0.021506   \n",
       "3      am  ...                           5                 0.004573   \n",
       "4      am  ...                           5                 0.004573   \n",
       "\n",
       "              opera_by_composer performances_season_by_country_total  \\\n",
       "0  Ali Pascha von Janina by Lor                                  110   \n",
       "1           Don Giovanni by Moz                                  110   \n",
       "2                  Tosca by Puc                                  110   \n",
       "3                 Almast by Spe                                  111   \n",
       "4                 Anoush by Tig                                  111   \n",
       "\n",
       "   performances_season_by_city_total  perf_total_per_1k_city_pop  \\\n",
       "0                                110                    0.262847   \n",
       "1                                110                    0.262847   \n",
       "2                                110                    0.262847   \n",
       "3                                111                    0.101510   \n",
       "4                                111                    0.101510   \n",
       "\n",
       "  perf_total_per_10k_co_pop Season Year  country_change_from_previous_season  \\\n",
       "0                  0.385301  2013-01-01                                  NaN   \n",
       "1                  0.385301  2013-01-01                                  NaN   \n",
       "2                  0.385301  2013-01-01                                  NaN   \n",
       "3                  0.371147  2013-01-01                                  NaN   \n",
       "4                  0.371147  2013-01-01                                  NaN   \n",
       "\n",
       "   city_change_from_previous_season  \n",
       "0                               NaN  \n",
       "1                               NaN  \n",
       "2                               NaN  \n",
       "3                               NaN  \n",
       "4                               NaN  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opera = pd.read_excel('/Users/angelique/Documents/GitHub/New_Opera_Company_Capstone/Excel and CSV Files/opera_4.xlsx')\n",
    "opera.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c10859f5-efe4-4080-85cf-0d84b8c6035b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['season', 'iso', 'city', 'composer', 'db', 'dd', 'nat', 'mf', 'work',\n",
       "       'worknat', 'type', 'start date', 'performances', 'Country Name',\n",
       "       'city population', 'country population', 'continent', 'sub-region',\n",
       "       'performances_season_by_country', 'perf_per_10k_ppl_co_pop',\n",
       "       'performances_season_by_city', 'perf_per_1k_ppl_city_pop',\n",
       "       'opera_by_composer', 'performances_season_by_country_total',\n",
       "       'performances_season_by_city_total', 'perf_total_per_1k_city_pop',\n",
       "       'perf_total_per_10k_co_pop', 'Season Year',\n",
       "       'country_change_from_previous_season',\n",
       "       'city_change_from_previous_season'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opera.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90bcf431-c363-47ae-9b09-3781e993e7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season                                           int64\n",
       "iso                                             object\n",
       "city                                            object\n",
       "composer                                        object\n",
       "db                                              object\n",
       "dd                                              object\n",
       "nat                                             object\n",
       "mf                                              object\n",
       "work                                            object\n",
       "worknat                                         object\n",
       "type                                            object\n",
       "start date                              datetime64[ns]\n",
       "performances                                     int64\n",
       "Country Name                                    object\n",
       "city population                                  int64\n",
       "country population                             float64\n",
       "continent                                       object\n",
       "sub-region                                      object\n",
       "performances_season_by_country                   int64\n",
       "perf_per_10k_ppl_co_pop                        float64\n",
       "performances_season_by_city                      int64\n",
       "perf_per_1k_ppl_city_pop                       float64\n",
       "opera_by_composer                               object\n",
       "performances_season_by_country_total             int64\n",
       "performances_season_by_city_total                int64\n",
       "perf_total_per_1k_city_pop                     float64\n",
       "perf_total_per_10k_co_pop                      float64\n",
       "Season Year                             datetime64[ns]\n",
       "country_change_from_previous_season            float64\n",
       "city_change_from_previous_season               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opera.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7c8b24f-6f63-4ba3-8431-b2274f1be84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>iso</th>\n",
       "      <th>city</th>\n",
       "      <th>composer</th>\n",
       "      <th>db</th>\n",
       "      <th>dd</th>\n",
       "      <th>nat</th>\n",
       "      <th>mf</th>\n",
       "      <th>work</th>\n",
       "      <th>worknat</th>\n",
       "      <th>...</th>\n",
       "      <th>perf_total_per_10k_co_pop</th>\n",
       "      <th>Season Year</th>\n",
       "      <th>country_change_from_previous_season</th>\n",
       "      <th>city_change_from_previous_season</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Week_of_Year</th>\n",
       "      <th>Days_Since_Start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1213</td>\n",
       "      <td>al</td>\n",
       "      <td>Tirana</td>\n",
       "      <td>Lortzing</td>\n",
       "      <td>1801</td>\n",
       "      <td>1851</td>\n",
       "      <td>de</td>\n",
       "      <td>m</td>\n",
       "      <td>Ali Pascha von Janina</td>\n",
       "      <td>de</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385301</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1213</td>\n",
       "      <td>al</td>\n",
       "      <td>Tirana</td>\n",
       "      <td>Mozart</td>\n",
       "      <td>1756</td>\n",
       "      <td>1791</td>\n",
       "      <td>at</td>\n",
       "      <td>m</td>\n",
       "      <td>Don Giovanni</td>\n",
       "      <td>it</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385301</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1213</td>\n",
       "      <td>al</td>\n",
       "      <td>Tirana</td>\n",
       "      <td>Puccini</td>\n",
       "      <td>1858</td>\n",
       "      <td>1924</td>\n",
       "      <td>it</td>\n",
       "      <td>m</td>\n",
       "      <td>Tosca</td>\n",
       "      <td>it</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385301</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1213</td>\n",
       "      <td>am</td>\n",
       "      <td>Yerevan</td>\n",
       "      <td>Spendiaryan</td>\n",
       "      <td>1871</td>\n",
       "      <td>1928</td>\n",
       "      <td>am</td>\n",
       "      <td>m</td>\n",
       "      <td>Almast</td>\n",
       "      <td>am</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371147</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1213</td>\n",
       "      <td>am</td>\n",
       "      <td>Yerevan</td>\n",
       "      <td>Tigranian</td>\n",
       "      <td>1879</td>\n",
       "      <td>1950</td>\n",
       "      <td>am</td>\n",
       "      <td>m</td>\n",
       "      <td>Anoush</td>\n",
       "      <td>am</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371147</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   season iso     city     composer    db    dd nat mf                   work  \\\n",
       "0    1213  al   Tirana     Lortzing  1801  1851  de  m  Ali Pascha von Janina   \n",
       "1    1213  al   Tirana       Mozart  1756  1791  at  m           Don Giovanni   \n",
       "2    1213  al   Tirana      Puccini  1858  1924  it  m                  Tosca   \n",
       "3    1213  am  Yerevan  Spendiaryan  1871  1928  am  m                 Almast   \n",
       "4    1213  am  Yerevan    Tigranian  1879  1950  am  m                 Anoush   \n",
       "\n",
       "  worknat  ... perf_total_per_10k_co_pop Season Year  \\\n",
       "0      de  ...                  0.385301  2013-01-01   \n",
       "1      it  ...                  0.385301  2013-01-01   \n",
       "2      it  ...                  0.385301  2013-01-01   \n",
       "3      am  ...                  0.371147  2013-01-01   \n",
       "4      am  ...                  0.371147  2013-01-01   \n",
       "\n",
       "   country_change_from_previous_season city_change_from_previous_season  Year  \\\n",
       "0                                  NaN                              NaN  2013   \n",
       "1                                  NaN                              NaN  2013   \n",
       "2                                  NaN                              NaN  2013   \n",
       "3                                  NaN                              NaN  2013   \n",
       "4                                  NaN                              NaN  2013   \n",
       "\n",
       "   Month Day Weekday  Week_of_Year  Days_Since_Start  \n",
       "0      3  23       5            12               273  \n",
       "1      5  18       5            20               329  \n",
       "2      2  13       2             7               235  \n",
       "3      7  11       3            28               383  \n",
       "4      5  11       5            19               322  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opera['Year'] = opera['start date'].dt.year\n",
    "opera['Month'] = opera['start date'].dt.month\n",
    "opera['Day'] = opera['start date'].dt.day\n",
    "opera['Weekday'] = opera['start date'].dt.weekday\n",
    "opera['Week_of_Year'] = opera['start date'].dt.isocalendar().week\n",
    "opera['Days_Since_Start'] = (opera['start date'] - opera['start date'].min()).dt.days\n",
    "opera.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2350bdd4-f0d1-4c27-887d-c53a313a1587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['season', 'iso', 'city', 'composer', 'db', 'dd', 'nat', 'mf', 'work',\n",
       "       'worknat', 'type', 'start date', 'performances', 'Country Name',\n",
       "       'city population', 'country population', 'continent', 'sub-region',\n",
       "       'performances_season_by_country', 'perf_per_10k_ppl_co_pop',\n",
       "       'performances_season_by_city', 'perf_per_1k_ppl_city_pop',\n",
       "       'opera_by_composer', 'performances_season_by_country_total',\n",
       "       'performances_season_by_city_total', 'perf_total_per_1k_city_pop',\n",
       "       'perf_total_per_10k_co_pop', 'Season Year',\n",
       "       'country_change_from_previous_season',\n",
       "       'city_change_from_previous_season', 'Year', 'Month', 'Day', 'Weekday',\n",
       "       'Week_of_Year', 'Days_Since_Start'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opera.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d4a4b96-f4f9-4e40-bbac-3252164e0ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               city iso  city_change_from_previous_season\n",
      "748          Moscow  ru                           27911.0\n",
      "1216     Washington  us                           16128.0\n",
      "1062  St Petersburg  ru                            9681.0\n",
      "51        Arlington  us                            9648.0\n",
      "263        Columbus  us                            3549.0\n",
      "759         MÃ¼nchen  de                            3381.0\n",
      "931        Richmond  us                            3042.0\n",
      "846           Paris  fr                            2971.0\n",
      "868    Philadelphia  us                            2916.0\n",
      "327      Dusseldorf  de                            1677.0\n",
      "315         Dresden  de                            1674.0\n",
      "892     Portland OR  us                            1539.0\n",
      "62          Atlanta  us                            1312.0\n",
      "295          Denver  us                            1168.0\n",
      "371         Firenze  it                            1163.0\n",
      "1204       Voronezh  ru                             979.0\n",
      "290          Dayton  us                             968.0\n",
      "538         Jackson  us                             900.0\n",
      "642            Linz  at                             866.0\n",
      "687          Madrid  es                             861.0\n",
      "460           Halle  de                             820.0\n",
      "383       Frankfurt  de                             817.0\n",
      "95        Barcelona  es                             765.0\n",
      "869         Phoenix  us                             720.0\n",
      "605       Lancaster  us                             720.0\n"
     ]
    }
   ],
   "source": [
    "# Rank cities based on the sum of growth in performances\n",
    "opera_city_growth = opera[['city', 'city_change_from_previous_season', 'iso']]\n",
    "\n",
    "# Group by city and iso, and sum the 'city_change_from_previous_season' for each city\n",
    "city_growth_sum = opera_city_growth.groupby(['city', 'iso'], as_index=False)['city_change_from_previous_season'].sum()\n",
    "\n",
    "# Sort cities by total growth (sum), highest growth first\n",
    "city_growth_sorted = city_growth_sum.sort_values(by='city_change_from_previous_season', ascending=False)\n",
    "\n",
    "# Drop duplicates and keep the row with the highest growth for each city\n",
    "opera_city_growth_unique = city_growth_sorted.drop_duplicates(subset='city', keep='first')\n",
    "\n",
    "# Get the top cities with the highest total growth\n",
    "top_cities = opera_city_growth_unique.head(25)  # Top 10 cities with the highest total growth\n",
    "\n",
    "# Print the result\n",
    "print(top_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0ede498-2ab2-4104-aa35-10cd12d0561d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Country Name iso  country_change_from_previous_season\n",
      "58  Russian Federation  ru                             194425.0\n",
      "34               Italy  it                              87941.0\n",
      "65              Sweden  se                               6459.0\n",
      "55              Poland  pl                               5653.0\n",
      "64               Spain  es                               3115.0\n",
      "50         Netherlands  nl                               2892.0\n",
      "35               Japan  jp                                631.0\n",
      "39              Latvia  lv                                529.0\n",
      "23             Estonia  ee                                517.0\n",
      "62            Slovenia  si                                509.0\n",
      "6              Belarus  by                                450.0\n",
      "73          Uzbekistan  uz                                450.0\n",
      "2              Armenia  am                                442.0\n",
      "13               China  cn                                396.0\n",
      "59              Serbia  rs                                372.0\n",
      "1            Argentina  ar                                288.0\n",
      "37  Korea, Republic of  kr                                211.0\n",
      "49            Mongolia  mn                                180.0\n",
      "32             Ireland  ie                                177.0\n",
      "20             Denmark  dk                                165.0\n",
      "0              Albania  al                                115.0\n",
      "26             Georgia  ge                                111.0\n",
      "46              Mexico  mx                                 91.0\n",
      "51         New Zealand  nz                                 73.0\n",
      "36          Kazakhstan  kz                                 66.0\n"
     ]
    }
   ],
   "source": [
    "# Rank countries based on the sum of growth in performances\n",
    "opera_country_growth = opera[['Country Name', 'country_change_from_previous_season', 'iso']]\n",
    "\n",
    "# Group by country and iso, and sum the 'country_change_from_previous_season' for each country\n",
    "country_growth_sum = opera_country_growth.groupby(['Country Name', 'iso'], as_index=False)['country_change_from_previous_season'].sum()\n",
    "\n",
    "# Sort countries by total growth (sum), highest growth first\n",
    "country_growth_sorted = country_growth_sum.sort_values(by='country_change_from_previous_season', ascending=False)\n",
    "\n",
    "# Drop duplicates and keep the row with the highest growth for each city\n",
    "opera_country_growth_unique = country_growth_sorted.drop_duplicates(subset='Country Name', keep='first')\n",
    "\n",
    "# Get the top cities with the highest total growth\n",
    "top_countries = opera_country_growth_unique.head(25)  # Top 10 cities with the highest total growth\n",
    "\n",
    "# Print the result\n",
    "print(top_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ff10f9a-ffbd-44c6-907c-e6de178876f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "season                                     0\n",
      "iso                                        0\n",
      "city                                       0\n",
      "composer                                   5\n",
      "db                                       227\n",
      "dd                                      3593\n",
      "nat                                       11\n",
      "mf                                         0\n",
      "work                                       5\n",
      "worknat                                 1548\n",
      "type                                       0\n",
      "start date                                 0\n",
      "performances                               0\n",
      "Country Name                               0\n",
      "city population                            0\n",
      "country population                         0\n",
      "continent                                  0\n",
      "sub-region                                 0\n",
      "performances_season_by_country             0\n",
      "perf_per_10k_ppl_co_pop                    0\n",
      "performances_season_by_city                0\n",
      "perf_per_1k_ppl_city_pop                   0\n",
      "opera_by_composer                          5\n",
      "performances_season_by_country_total       0\n",
      "performances_season_by_city_total          0\n",
      "perf_total_per_1k_city_pop                 0\n",
      "perf_total_per_10k_co_pop                  0\n",
      "Season Year                                0\n",
      "country_change_from_previous_season     6559\n",
      "city_change_from_previous_season        7191\n",
      "Year                                       0\n",
      "Month                                      0\n",
      "Day                                        0\n",
      "Weekday                                    0\n",
      "Week_of_Year                               0\n",
      "Days_Since_Start                           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_count_per_column = opera.isna().sum()\n",
    "print(nan_count_per_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "871012d9-d922-4737-b9bf-e1fafd36a3f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infinity counts per numeric column:\n",
      "season                                  0\n",
      "performances                            0\n",
      "city population                         0\n",
      "country population                      0\n",
      "performances_season_by_country          0\n",
      "perf_per_10k_ppl_co_pop                 0\n",
      "performances_season_by_city             0\n",
      "perf_per_1k_ppl_city_pop                0\n",
      "performances_season_by_country_total    0\n",
      "performances_season_by_city_total       0\n",
      "perf_total_per_1k_city_pop              0\n",
      "perf_total_per_10k_co_pop               0\n",
      "country_change_from_previous_season     0\n",
      "city_change_from_previous_season        0\n",
      "Year                                    0\n",
      "Month                                   0\n",
      "Day                                     0\n",
      "Weekday                                 0\n",
      "Week_of_Year                            0\n",
      "Days_Since_Start                        0\n",
      "dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Select only numeric columns\n",
    "numeric_columns = opera.select_dtypes(include=[np.number])\n",
    "\n",
    "# Step 2: Check for infinity values in the numeric columns\n",
    "infinity_counts = np.isinf(numeric_columns).sum()\n",
    "\n",
    "# Step 3: Print the count of infinity values per numeric column\n",
    "print(\"Infinity counts per numeric column:\")\n",
    "print(infinity_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8eb3106-b2da-4d65-ad7b-af10c2fa55dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the condition for selecting rows\n",
    "condition = (opera['iso'] == 'cu') & (opera['city'] == 'La Habana')\n",
    "\n",
    "# Apply fillna() to the 'country_change_from_previous_season' column for the selected rows\n",
    "opera.loc[condition, 'country_change_from_previous_season'] = opera.loc[\n",
    "    condition, 'country_change_from_previous_season'\n",
    "].fillna(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1813f5e-8003-4f6d-a622-b0d1cac94071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       season iso       city composer    db    dd nat mf          work  \\\n",
      "27083    1617  cu  La Habana   Mozart  1756  1791  at  m  Don Giovanni   \n",
      "\n",
      "      worknat  ... perf_total_per_10k_co_pop Season Year  \\\n",
      "27083      it  ...                  0.001783  2017-01-01   \n",
      "\n",
      "       country_change_from_previous_season city_change_from_previous_season  \\\n",
      "27083                                  2.0                              NaN   \n",
      "\n",
      "       Year  Month Day Weekday  Week_of_Year  Days_Since_Start  \n",
      "27083  2016     12  17       5            50              1638  \n",
      "\n",
      "[1 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display rows where 'iso' is 'cu' and 'city' is 'La Habana'\n",
    "print(opera[(opera['iso'] == 'cu') & (opera['city'] == 'La Habana')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "167720f7-981b-4af6-9164-8d5fb7663595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of country_missing: 6558\n",
      "Length of predicted values: 6558\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Identify rows with missing values in 'country_change_from_previous_season'\n",
    "country_missing = opera[opera['country_change_from_previous_season'].isna()]\n",
    "\n",
    "# Step 2: Use rows without missing values to train the model\n",
    "country_not_missing = opera.dropna(subset=['country_change_from_previous_season'])\n",
    "\n",
    "# Separate features (X) and target (y) for rows without missing values\n",
    "X_no_missing = country_not_missing[['city population', 'country population', 'performances_season_by_country', \n",
    "                                    'perf_per_10k_ppl_co_pop', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', \n",
    "                                    'Year']]\n",
    "y_no_missing = country_not_missing['country_change_from_previous_season']\n",
    "\n",
    "# Step 3: Train the Linear Regression Model for each iso\n",
    "predicted_values = []\n",
    "\n",
    "# Group the data by 'iso' and perform the prediction for each group\n",
    "for iso_code, group in country_not_missing.groupby('iso'):\n",
    "    # Separate the group into features (X) and target (y)\n",
    "    X_group = group[['city population', 'country population', 'performances_season_by_country', \n",
    "                     'perf_per_10k_ppl_co_pop', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', 'Year']]\n",
    "    y_group = group['country_change_from_previous_season']\n",
    "    \n",
    "    # Train the linear regression model for this specific iso code\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_group, y_group)\n",
    "    \n",
    "    # Get the rows for this iso code that have missing values\n",
    "    missing_group = country_missing[country_missing['iso'] == iso_code]\n",
    "    \n",
    "    # If there are any missing values for this iso, predict them\n",
    "    if not missing_group.empty:\n",
    "        X_missing = missing_group[['city population', 'country population', 'performances_season_by_country', \n",
    "                                  'perf_per_10k_ppl_co_pop', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', 'Year']]\n",
    "        \n",
    "        # Predict the missing values\n",
    "        predictions = model.predict(X_missing)\n",
    "        \n",
    "        # Store the predicted values and add to the list\n",
    "        predicted_values.extend(predictions)\n",
    "\n",
    "# Step 4: Check the lengths to confirm they match\n",
    "print(f\"Length of country_missing: {len(country_missing)}\")\n",
    "print(f\"Length of predicted values: {len(predicted_values)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52762436-b7f0-4495-af25-82e923e5b809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       season iso     city        composer    db    dd nat mf  \\\n",
      "0        1213  al   Tirana        Lortzing  1801  1851  de  m   \n",
      "1        1213  al   Tirana          Mozart  1756  1791  at  m   \n",
      "2        1213  al   Tirana         Puccini  1858  1924  it  m   \n",
      "3        1213  am  Yerevan     Spendiaryan  1871  1928  am  m   \n",
      "4        1213  am  Yerevan       Tigranian  1879  1950  am  m   \n",
      "...       ...  ..      ...             ...   ...   ...  .. ..   \n",
      "10091    1314  kz   Astana           Verdi  1813  1901  it  m   \n",
      "10240    1314  mo    Macau          Mozart  1756  1791  at  m   \n",
      "10241    1314  mo    Macau           Verdi  1813  1901  it  m   \n",
      "10242    1314  mo    Macau           Verdi  1813  1901  it  m   \n",
      "10243    1314  mo    Macau  Wagner,Richard  1813  1883  de  m   \n",
      "\n",
      "                        work worknat  ... perf_total_per_10k_co_pop  \\\n",
      "0      Ali Pascha von Janina      de  ...                  0.385301   \n",
      "1               Don Giovanni      it  ...                  0.385301   \n",
      "2                      Tosca      it  ...                  0.385301   \n",
      "3                     Almast      am  ...                  0.371147   \n",
      "4                     Anoush      am  ...                  0.371147   \n",
      "...                      ...     ...  ...                       ...   \n",
      "10091                 Attila      it  ...                  0.116293   \n",
      "10240  Bastien und Bastienne      de  ...                  0.452592   \n",
      "10241                   Aida      it  ...                  0.452592   \n",
      "10242                Requiem      it  ...                  0.452592   \n",
      "10243          Das Rheingold      de  ...                  0.452592   \n",
      "\n",
      "      Season Year  country_change_from_previous_season  \\\n",
      "0      2013-01-01                             2.230995   \n",
      "1      2013-01-01                             2.230995   \n",
      "2      2013-01-01                             2.230995   \n",
      "3      2013-01-01                             0.000000   \n",
      "4      2013-01-01                             0.000000   \n",
      "...           ...                                  ...   \n",
      "10091  2014-01-01                             5.547862   \n",
      "10240  2014-01-01                             6.592633   \n",
      "10241  2014-01-01                             5.547862   \n",
      "10242  2014-01-01                             6.592633   \n",
      "10243  2014-01-01                             6.592633   \n",
      "\n",
      "      city_change_from_previous_season  Year  Month Day Weekday  Week_of_Year  \\\n",
      "0                                  NaN  2013      3  23       5            12   \n",
      "1                                  NaN  2013      5  18       5            20   \n",
      "2                                  NaN  2013      2  13       2             7   \n",
      "3                                  NaN  2013      7  11       3            28   \n",
      "4                                  NaN  2013      5  11       5            19   \n",
      "...                                ...   ...    ...  ..     ...           ...   \n",
      "10091                              NaN  2013     12  16       0            51   \n",
      "10240                              NaN  2013     10  13       6            41   \n",
      "10241                              NaN  2013     10  11       4            41   \n",
      "10242                              NaN  2013     10   5       5            40   \n",
      "10243                              NaN  2013     10   2       2            40   \n",
      "\n",
      "       Days_Since_Start  \n",
      "0                   273  \n",
      "1                   329  \n",
      "2                   235  \n",
      "3                   383  \n",
      "4                   322  \n",
      "...                 ...  \n",
      "10091               541  \n",
      "10240               477  \n",
      "10241               475  \n",
      "10242               469  \n",
      "10243               466  \n",
      "\n",
      "[6558 rows x 36 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v8/j1kjtws546j8drwljwyklgrm0000gn/T/ipykernel_82872/1160055947.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  country_missing['country_change_from_previous_season'] = predicted_values\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Assign the predicted values to the original DataFrame\n",
    "country_missing['country_change_from_previous_season'] = predicted_values\n",
    "\n",
    "# Print the updated dataframe with predicted values\n",
    "print(country_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6a25337-ec61-40b6-921c-f715a652acd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   season iso     city     composer    db    dd nat mf                   work  \\\n",
      "0    1213  al   Tirana     Lortzing  1801  1851  de  m  Ali Pascha von Janina   \n",
      "1    1213  al   Tirana       Mozart  1756  1791  at  m           Don Giovanni   \n",
      "2    1213  al   Tirana      Puccini  1858  1924  it  m                  Tosca   \n",
      "3    1213  am  Yerevan  Spendiaryan  1871  1928  am  m                 Almast   \n",
      "4    1213  am  Yerevan    Tigranian  1879  1950  am  m                 Anoush   \n",
      "\n",
      "  worknat  ... perf_total_per_10k_co_pop Season Year  \\\n",
      "0      de  ...                  0.385301  2013-01-01   \n",
      "1      it  ...                  0.385301  2013-01-01   \n",
      "2      it  ...                  0.385301  2013-01-01   \n",
      "3      am  ...                  0.371147  2013-01-01   \n",
      "4      am  ...                  0.371147  2013-01-01   \n",
      "\n",
      "   country_change_from_previous_season city_change_from_previous_season  Year  \\\n",
      "0                             2.230995                              NaN  2013   \n",
      "1                             2.230995                              NaN  2013   \n",
      "2                             2.230995                              NaN  2013   \n",
      "3                             0.000000                              NaN  2013   \n",
      "4                             0.000000                              NaN  2013   \n",
      "\n",
      "   Month Day Weekday  Week_of_Year  Days_Since_Start  \n",
      "0      3  23       5            12               273  \n",
      "1      5  18       5            20               329  \n",
      "2      2  13       2             7               235  \n",
      "3      7  11       3            28               383  \n",
      "4      5  11       5            19               322  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Fill the missing values with the predicted values\n",
    "opera.loc[opera['country_change_from_previous_season'].isna(), 'country_change_from_previous_season'] = predicted_values\n",
    "\n",
    "# Now 'df' has the missing values in 'country_change_from_previous_season' filled\n",
    "print(opera.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73220c2c-1add-40cd-9026-08358551a049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "season                                     0\n",
      "iso                                        0\n",
      "city                                       0\n",
      "composer                                   5\n",
      "db                                       227\n",
      "dd                                      3593\n",
      "nat                                       11\n",
      "mf                                         0\n",
      "work                                       5\n",
      "worknat                                 1548\n",
      "type                                       0\n",
      "start date                                 0\n",
      "performances                               0\n",
      "Country Name                               0\n",
      "city population                            0\n",
      "country population                         0\n",
      "continent                                  0\n",
      "sub-region                                 0\n",
      "performances_season_by_country             0\n",
      "perf_per_10k_ppl_co_pop                    0\n",
      "performances_season_by_city                0\n",
      "perf_per_1k_ppl_city_pop                   0\n",
      "opera_by_composer                          5\n",
      "performances_season_by_country_total       0\n",
      "performances_season_by_city_total          0\n",
      "perf_total_per_1k_city_pop                 0\n",
      "perf_total_per_10k_co_pop                  0\n",
      "Season Year                                0\n",
      "country_change_from_previous_season        0\n",
      "city_change_from_previous_season        7191\n",
      "Year                                       0\n",
      "Month                                      0\n",
      "Day                                        0\n",
      "Weekday                                    0\n",
      "Week_of_Year                               0\n",
      "Days_Since_Start                           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_count_per_column = opera.isna().sum()\n",
    "print(nan_count_per_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96ff3201-8fd0-4287-9147-37a76e6cfc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the condition for selecting rows\n",
    "condition = (opera['iso'] == 'cu') & (opera['city'] == 'La Habana')\n",
    "\n",
    "# Apply fillna() to the 'country_change_from_previous_season' column for the selected rows\n",
    "opera.loc[condition, 'city_change_from_previous_season'] = opera.loc[\n",
    "    condition, 'city_change_from_previous_season'\n",
    "].fillna(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f06e2fa-ed39-47cf-9960-9d2d70fee194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of city_missing: 7190\n",
      "Length of predicted values: 7190\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Identify rows with missing values in 'city_change_from_previous_season'\n",
    "city_missing = opera[opera['city_change_from_previous_season'].isna()]\n",
    "\n",
    "# Step 2: Use rows without missing values to train the model\n",
    "city_not_missing = opera.dropna(subset=['city_change_from_previous_season'])\n",
    "\n",
    "# Separate features (X) and target (y) for rows without missing values\n",
    "X_no_missing = city_not_missing[['city population', 'country population', 'performances_season_by_country', \n",
    "                                    'perf_per_10k_ppl_co_pop', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', \n",
    "                                    'Year']]\n",
    "y_no_missing = city_not_missing['city_change_from_previous_season']\n",
    "\n",
    "# Step 3: Train the Linear Regression Model for each iso\n",
    "predicted_values = []\n",
    "\n",
    "# Group the data by 'iso' and perform the prediction for each group\n",
    "for iso_code, group in city_not_missing.groupby('iso'):\n",
    "    # Separate the group into features (X) and target (y)\n",
    "    X_group = group[['city population', 'country population', 'performances_season_by_country', \n",
    "                     'perf_per_10k_ppl_co_pop', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', 'Year']]\n",
    "    y_group = group['city_change_from_previous_season']\n",
    "    \n",
    "    # Train the linear regression model for this specific iso code\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_group, y_group)\n",
    "    \n",
    "    # Get the rows for this iso code that have missing values\n",
    "    missing_group = city_missing[city_missing['iso'] == iso_code]\n",
    "    \n",
    "    # If there are any missing values for this iso, predict them\n",
    "    if not missing_group.empty:\n",
    "        X_missing = missing_group[['city population', 'country population', 'performances_season_by_country', \n",
    "                                  'perf_per_10k_ppl_co_pop', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', 'Year']]\n",
    "        \n",
    "        # Predict the missing values\n",
    "        predictions = model.predict(X_missing)\n",
    "        \n",
    "        # Store the predicted values and add to the list\n",
    "        predicted_values.extend(predictions)\n",
    "\n",
    "# Step 4: Check the lengths to confirm they match\n",
    "print(f\"Length of city_missing: {len(city_missing)}\")\n",
    "print(f\"Length of predicted values: {len(predicted_values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "667f508c-09b4-4bc3-820e-0910742924d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   season iso     city     composer    db    dd nat mf                   work  \\\n",
      "0    1213  al   Tirana     Lortzing  1801  1851  de  m  Ali Pascha von Janina   \n",
      "1    1213  al   Tirana       Mozart  1756  1791  at  m           Don Giovanni   \n",
      "2    1213  al   Tirana      Puccini  1858  1924  it  m                  Tosca   \n",
      "3    1213  am  Yerevan  Spendiaryan  1871  1928  am  m                 Almast   \n",
      "4    1213  am  Yerevan    Tigranian  1879  1950  am  m                 Anoush   \n",
      "\n",
      "  worknat  ... perf_total_per_10k_co_pop Season Year  \\\n",
      "0      de  ...                  0.385301  2013-01-01   \n",
      "1      it  ...                  0.385301  2013-01-01   \n",
      "2      it  ...                  0.385301  2013-01-01   \n",
      "3      am  ...                  0.371147  2013-01-01   \n",
      "4      am  ...                  0.371147  2013-01-01   \n",
      "\n",
      "   country_change_from_previous_season city_change_from_previous_season  Year  \\\n",
      "0                             2.230995                         2.230995  2013   \n",
      "1                             2.230995                         2.230995  2013   \n",
      "2                             2.230995                         2.230995  2013   \n",
      "3                             0.000000                         0.000000  2013   \n",
      "4                             0.000000                         0.000000  2013   \n",
      "\n",
      "   Month Day Weekday  Week_of_Year  Days_Since_Start  \n",
      "0      3  23       5            12               273  \n",
      "1      5  18       5            20               329  \n",
      "2      2  13       2             7               235  \n",
      "3      7  11       3            28               383  \n",
      "4      5  11       5            19               322  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Fill the missing values with the predicted values\n",
    "opera.loc[opera['city_change_from_previous_season'].isna(), 'city_change_from_previous_season'] = predicted_values\n",
    "\n",
    "# Now 'df' has the missing values in 'country_change_from_previous_season' filled\n",
    "print(opera.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea45b623-9d09-468a-bc6f-703e7b9d7806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "season                                     0\n",
      "iso                                        0\n",
      "city                                       0\n",
      "composer                                   5\n",
      "db                                       227\n",
      "dd                                      3593\n",
      "nat                                       11\n",
      "mf                                         0\n",
      "work                                       5\n",
      "worknat                                 1548\n",
      "type                                       0\n",
      "start date                                 0\n",
      "performances                               0\n",
      "Country Name                               0\n",
      "city population                            0\n",
      "country population                         0\n",
      "continent                                  0\n",
      "sub-region                                 0\n",
      "performances_season_by_country             0\n",
      "perf_per_10k_ppl_co_pop                    0\n",
      "performances_season_by_city                0\n",
      "perf_per_1k_ppl_city_pop                   0\n",
      "opera_by_composer                          5\n",
      "performances_season_by_country_total       0\n",
      "performances_season_by_city_total          0\n",
      "perf_total_per_1k_city_pop                 0\n",
      "perf_total_per_10k_co_pop                  0\n",
      "Season Year                                0\n",
      "country_change_from_previous_season        0\n",
      "city_change_from_previous_season           0\n",
      "Year                                       0\n",
      "Month                                      0\n",
      "Day                                        0\n",
      "Weekday                                    0\n",
      "Week_of_Year                               0\n",
      "Days_Since_Start                           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_count_per_column = opera.isna().sum()\n",
    "print(nan_count_per_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "84db532b-6de1-448e-8cfc-0325e6b44bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix,recall_score , accuracy_score, precision_score, roc_auc_score\n",
    "\n",
    "#Evaluate the model using accuracy, precision, and recall scores under evaluate_model fuction\n",
    "def evaluate_model(y_test, y_pred):\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(f\"Precision (macro): {precision_score(y_test, y_pred, average='macro')}\")\n",
    "    print(f\"Recall (macro): {recall_score(y_test, y_pred, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0009cd90-4f6d-4332-b682-7b17cf7dc1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "#Evaluate the model using mean absolute error, mean standard error, root mean square error and the rsquared score under lin_evaluate_model fuction\n",
    "def lin_evaluate_model(y_test, y_pred):\n",
    "    print(f\"MAE: {mean_absolute_error(y_test, y_pred)}\")\n",
    "    print(f\"MSE: {mean_squared_error(y_test, y_pred)}\")\n",
    "    print(f\"RMSE: {mean_squared_error(y_test, y_pred, squared=False)}\")\n",
    "    print(f\"R2_Score: {r2_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ee7efce2-6ce0-41b1-b000-a38544c14b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30630cfc-0559-4f37-994e-f06418e8497d",
   "metadata": {},
   "source": [
    "Linear Regression models - I ran these first without grouping by Country to help the predictive model just as a starting point to see how a linear regression model would perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6f090f37-06ec-4272-8422-605730ecdde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Country Name  predicted_country_growth\n",
      "2427                                  Finland                 64.602230\n",
      "4515                                 Slovenia                 64.268948\n",
      "3883                                  Romania                 62.971156\n",
      "263                                 Australia                 62.230289\n",
      "3390                                Lithuania                 62.071735\n",
      "3798                                   Poland                 57.128646\n",
      "639                               Switzerland                 52.964412\n",
      "16338                                 Hungary                 48.648625\n",
      "2523                                   France                 47.109120\n",
      "14269                          Czech Republic                 46.337339\n",
      "187                                   Austria                 44.077780\n",
      "16621                                   Italy                 37.711045\n",
      "3330                               Kyrgyzstan                 28.950386\n",
      "3460   Macedonia, The former Yugoslav Rep. of                 28.606890\n",
      "3474                                 Mongolia                 28.478082\n",
      "3450                     Moldova, Republic of                 28.007704\n",
      "3640                                     Oman                 27.737217\n",
      "2801                                  Georgia                 27.541811\n",
      "3976                                   Serbia                 27.481696\n",
      "2951                                  Ireland                 27.370718\n",
      "2274                                    Egypt                 26.399693\n",
      "3812                                 Portugal                 26.293885\n",
      "283                                Azerbaijan                 26.145849\n",
      "540                                   Belarus                 25.796884\n",
      "298                    Bosnia and Herzegovina                 25.014628\n"
     ]
    }
   ],
   "source": [
    "# Independent variables (predictors)\n",
    "X_country = opera[['country population', 'performances_season_by_country', \n",
    "           'perf_per_10k_ppl_co_pop', 'Year', 'Month', 'Day', 'Weekday', 'Week_of_Year', 'Days_Since_Start']]\n",
    "\n",
    "# Dependent variable (growth at country level)\n",
    "y_country = opera['country_change_from_previous_season']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train_country, y_test_country = train_test_split(X_country, y_country, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data (using the same scaler as the training data)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Model for country growth prediction\n",
    "lin_country = LinearRegression()\n",
    "\n",
    "# Train the model on scaled data\n",
    "lin_country.fit(X_train_scaled, y_train_country)\n",
    "\n",
    "# Transform the entire country data to scaled values before prediction (using the same scaler)\n",
    "X_country_scaled = scaler.transform(X_country)\n",
    "\n",
    "# Predict growth for the entire country dataset\n",
    "opera['predicted_country_growth'] = lin_country.predict(X_country_scaled)\n",
    "\n",
    "# Sort countries based on predicted growth\n",
    "df_country_growth_sorted = opera[['Country Name', 'predicted_country_growth']].sort_values(by='predicted_country_growth', ascending=False)\n",
    "\n",
    "# Drop duplicates and keep the row with the highest growth for each city\n",
    "df_opera_country_growth_unique = df_country_growth_sorted.drop_duplicates(subset='Country Name', keep='first')\n",
    "\n",
    "# Get top 10 countries with highest predicted growth\n",
    "top_countries_predicted = df_opera_country_growth_unique.head(10)\n",
    "print(top_countries_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3979f988-f03f-4459-90e3-0e3c6fa06c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 147.4464666762436\n",
      "MSE: 41427.254873078375\n",
      "RMSE: 203.53686367112562\n",
      "R2_Score: 0.03462941940354791\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction\n",
    "y_pred_country_lin = lin_country.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate model\n",
    "lin_evaluate_model(y_test_country, y_pred_country_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2ea2c806-91e9-48e7-879e-851a02cd9d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      iso               city  predicted_city_growth\n",
      "639    ch           Fribourg              50.940702\n",
      "2605   fr           MÃ©rignac              50.787857\n",
      "2523   fr  Lamalou les Bains              48.338138\n",
      "2714   fr             Rennes              47.699147\n",
      "4515   si            Maribor              46.049246\n",
      "12318  us             Eugene              45.843822\n",
      "10123  lt          Klaipedos              43.769687\n",
      "3883   ro        Cluj-Napoca              41.965372\n",
      "14515  de        Brandenburg              40.866290\n",
      "10484  pl           Szczecin              40.625619\n",
      "16621  it             Padova              40.561318\n",
      "16177  fr      Saint-Etienne              40.311624\n",
      "15992  fr            Limoges              39.971503\n",
      "14700  de           Eisenach              39.662011\n",
      "10736  ro          Timisoara              39.651198\n",
      "14112  ch         Winterthur              39.477674\n",
      "8531   de          Pforzheim              38.951153\n",
      "3390   lt            Vilnius              37.907909\n",
      "7660   de       Braunschweig              37.728053\n",
      "16065  fr              Nancy              37.489045\n",
      "15448  de            Rostock              37.376620\n",
      "17195  pl          Bialystok              37.128187\n",
      "10113  lt             Kaunas              35.885135\n",
      "14909  de              Halle              35.360488\n",
      "2427   fi           Helsinki              31.900526\n"
     ]
    }
   ],
   "source": [
    "# Independent variables (predictors)\n",
    "X_city = opera[['city population', 'performances_season_by_city', \n",
    "           'perf_per_1k_ppl_city_pop', 'Year', 'Month', 'Day', 'Weekday', 'Week_of_Year', 'Days_Since_Start']]\n",
    "\n",
    "# Dependent variable (growth at city level)\n",
    "y_city = opera['city_change_from_previous_season']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train_city, y_test_city = train_test_split(X_city, y_city, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data (using the same scaler as the training data)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Model for city growth prediction\n",
    "lin_city = LinearRegression()\n",
    "\n",
    "# Train the model on scaled data\n",
    "lin_city.fit(X_train_scaled, y_train_city)\n",
    "\n",
    "# Transform the entire city data to scaled values before prediction (using the same scaler)\n",
    "X_city_scaled = scaler.transform(X_city)\n",
    "\n",
    "# Predict growth for the entire city dataset\n",
    "opera['predicted_city_growth'] = lin_country.predict(X_city_scaled)\n",
    "\n",
    "# Sort cities based on predicted growth\n",
    "df_city_growth_sorted = opera[['iso', 'city', 'predicted_city_growth']].sort_values(by='predicted_city_growth', ascending=False)\n",
    "\n",
    "# Drop duplicates and keep the row with the highest growth for each city\n",
    "df_opera_city_growth_unique = df_city_growth_sorted.drop_duplicates(subset='city', keep='first')\n",
    "\n",
    "# Get top 25 cities with highest predicted growth\n",
    "top_cities_predicted = df_opera_city_growth_unique.head(10)\n",
    "print(top_cities_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9df4f37f-de92-47d0-8d7c-6a3b7af80920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 20.414874196048945\n",
      "MSE: 5383.527336497656\n",
      "RMSE: 73.3725243977448\n",
      "R2_Score: 0.003156693027542623\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction\n",
    "y_pred_city_lin = lin_city.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate model\n",
    "lin_evaluate_model(y_test_city, y_pred_city_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077dd158-9c80-4238-9d4d-021df831b682",
   "metadata": {},
   "source": [
    "Linear Regression and grouping by country for predictive analysis. This time I grouped the opera data by countries before peforming the linear regression to see if it improved predictions.  The scores were significantly better for the cities prediction but they still were underperforming for the country data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "07535be7-df93-404a-b594-d67b6fd5a0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Country Name  predicted_country_growth\n",
      "10063          Kazakhstan                798.197515\n",
      "11336            Slovenia                643.610020\n",
      "11203  Russian Federation                509.827161\n",
      "13430       United States                405.193736\n",
      "8342              Germany                204.790420\n",
      "37186              Sweden                172.875446\n",
      "9476               Greece                166.491174\n",
      "8920                Spain                159.006531\n",
      "10389         New Zealand                132.320672\n",
      "23151               Italy                130.385863\n"
     ]
    }
   ],
   "source": [
    "# Independent variables (predictors)\n",
    "X_country = opera[['country population', 'performances_season_by_country', 'perf_per_10k_ppl_co_pop',\n",
    "                   'city population', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', 'Year', 'Month', 'Day', \n",
    "                   'Weekday', 'Week_of_Year', 'Days_Since_Start']]\n",
    "\n",
    "# Dependent variable (growth at country level)\n",
    "y_country = opera['country_change_from_previous_season']\n",
    "\n",
    "# Group by Country\n",
    "country_groups = opera.groupby('Country Name')\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Model for country growth prediction\n",
    "lin_country = LinearRegression()\n",
    "\n",
    "# Store the predicted values in a DataFrame\n",
    "predicted_growth_values = pd.Series(index=opera.index)  # Create an empty Series to store predictions\n",
    "\n",
    "# Loop through each country group to train and predict separately\n",
    "for country_name, group in country_groups:\n",
    "    # If the group has more than one sample, split and train\n",
    "    if len(group) > 1:\n",
    "        # Extract the features and target for this country group\n",
    "        X_group = group[['country population', 'performances_season_by_country', 'perf_per_10k_ppl_co_pop', \n",
    "                         'city population', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', 'Year', 'Month', 'Day', \n",
    "                         'Weekday', 'Week_of_Year', 'Days_Since_Start']]\n",
    "        y_group = group['country_change_from_previous_season']\n",
    "\n",
    "        # Split data into train and test sets (80% train, 20% test)\n",
    "        X_train, X_test, y_train_country, y_test_country = train_test_split(X_group, y_group, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Scale the training data\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "        # Train the model on the training data\n",
    "        lin_country.fit(X_train_scaled, y_train_country)\n",
    "\n",
    "        # Scale the test data using the same scaler\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # Make predictions for the test set\n",
    "        predictions = lin_country.predict(X_test_scaled)\n",
    "\n",
    "        # Assign predictions to the correct indices in the original DataFrame\n",
    "        predicted_growth_values.loc[X_test.index] = predictions  # Correctly assign predictions to test set rows\n",
    "    else:\n",
    "        # If the group has only one sample, predict directly and append\n",
    "        X_group = group[['country population', 'performances_season_by_country', 'perf_per_10k_ppl_co_pop', \n",
    "                         'city population', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', 'Year', 'Month', 'Day', \n",
    "                         'Weekday', 'Week_of_Year', 'Days_Since_Start']]\n",
    "        y_group = group['country_change_from_previous_season']\n",
    "        \n",
    "        # Scale the data for this group\n",
    "        X_scaled = scaler.fit_transform(X_group)\n",
    "\n",
    "        # Train the model\n",
    "        lin_country.fit(X_scaled, y_group)\n",
    "\n",
    "        # Make predictions for this group\n",
    "        predictions = lin_country.predict(X_scaled)\n",
    "        \n",
    "        # Assign predictions to the correct indices in the original DataFrame\n",
    "        predicted_growth_values.loc[group.index] = predictions  # Correctly assign predictions to the original rows\n",
    "\n",
    "# Assign the predicted values to the original DataFrame\n",
    "opera['predicted_country_growth'] = predicted_growth_values\n",
    "\n",
    "# Sort countries based on predicted growth\n",
    "df_country_growth_sorted = opera[['Country Name', 'predicted_country_growth']].sort_values(by='predicted_country_growth', ascending=False)\n",
    "\n",
    "# Drop duplicates and keep the row with the highest growth for each country\n",
    "df_opera_country_growth_unique = df_country_growth_sorted.drop_duplicates(subset='Country Name', keep='first')\n",
    "\n",
    "# Get top 10 countries with highest predicted growth\n",
    "top_countries_predicted = df_opera_country_growth_unique.head(10)\n",
    "print(top_countries_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "958e9637-d052-43af-a8b6-bcd08e1440ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 121.33249735135902\n",
      "MSE: 14721.574913517545\n",
      "RMSE: 121.33249735135902\n",
      "R2_Score: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction\n",
    "y_pred_country_lin = lin_country.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate model\n",
    "lin_evaluate_model(y_test_country, y_pred_country_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d23f7fad-c708-4366-a093-95340f84c61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      iso           city  predicted_city_growth\n",
      "9476   gr      Epidaurus             694.898107\n",
      "11336  si        Maribor             574.433912\n",
      "24445  sg      Singapore             155.016091\n",
      "29199  hu       Budapest             114.757264\n",
      "11203  ru  St Petersburg              91.087936\n",
      "10883  ru         Moscow              89.552933\n",
      "35274  fr         Orange              82.086091\n",
      "35113  fr         Beaune              77.591111\n",
      "35163  fr          Givet              76.030356\n",
      "35228  fr    Montpellier              75.168867\n"
     ]
    }
   ],
   "source": [
    "# Independent variables (predictors)\n",
    "X_city = opera[['country population', 'performances_season_by_country', 'perf_per_10k_ppl_co_pop',\n",
    "                   'city population', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', 'Year', 'Month', 'Day', \n",
    "                   'Weekday', 'Week_of_Year', 'Days_Since_Start']]\n",
    "\n",
    "# Dependent variable (growth at city level)\n",
    "y_city = opera['city_change_from_previous_season']\n",
    "\n",
    "# Group by Country\n",
    "city_groups = opera.groupby('Country Name')\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Model for country growth prediction\n",
    "lin_city = LinearRegression()\n",
    "\n",
    "# Store the predicted values in a DataFrame\n",
    "predicted_growth_values = pd.Series(index=opera.index)  # Create an empty Series to store predictions\n",
    "\n",
    "# Loop through each country group to train and predict separately\n",
    "for city_name, group in city_groups:\n",
    "    # If the group has more than one sample, split and train\n",
    "    if len(group) > 1:\n",
    "        # Extract the features and target for this country group\n",
    "        X_group = group[['country population', 'performances_season_by_country', 'perf_per_10k_ppl_co_pop', \n",
    "                         'city population', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', 'Year', 'Month', 'Day', \n",
    "                         'Weekday', 'Week_of_Year', 'Days_Since_Start']]\n",
    "        y_group = group['city_change_from_previous_season']\n",
    "\n",
    "        # Split data into train and test sets (80% train, 20% test)\n",
    "        X_train, X_test, y_train_city, y_test_city = train_test_split(X_group, y_group, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Scale the training data\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "        # Train the model on the training data\n",
    "        lin_city.fit(X_train_scaled, y_train_city)\n",
    "\n",
    "        # Scale the test data using the same scaler\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # Make predictions for the test set\n",
    "        predictions = lin_city.predict(X_test_scaled)\n",
    "\n",
    "        # Assign predictions to the correct indices in the original DataFrame\n",
    "        predicted_growth_values.loc[X_test.index] = predictions  # Correctly assign predictions to test set rows\n",
    "    else:\n",
    "        # If the group has only one sample, predict directly and append\n",
    "        X_group = group[['country population', 'performances_season_by_country', 'perf_per_10k_ppl_co_pop', \n",
    "                         'city population', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', 'Year', 'Month', 'Day', \n",
    "                         'Weekday', 'Week_of_Year', 'Days_Since_Start']]\n",
    "        y_group = group['city_change_from_previous_season']\n",
    "        \n",
    "        # Scale the data for this group\n",
    "        X_scaled = scaler.fit_transform(X_group)\n",
    "\n",
    "        # Train the model\n",
    "        lin_city.fit(X_scaled, y_group)\n",
    "\n",
    "        # Make predictions for this group\n",
    "        predictions = lin_city.predict(X_scaled)\n",
    "        \n",
    "        # Assign predictions to the correct indices in the original DataFrame\n",
    "        predicted_growth_values.loc[group.index] = predictions  # Correctly assign predictions to the original rows\n",
    "\n",
    "# Assign the predicted values to the original DataFrame\n",
    "opera['predicted_city_growth'] = predicted_growth_values\n",
    "\n",
    "# Sort countries based on predicted growth\n",
    "df_city_growth_sorted = opera[['iso', 'city', 'predicted_city_growth']].sort_values(by='predicted_city_growth', ascending=False)\n",
    "\n",
    "# Drop duplicates and keep the row with the highest growth for each country\n",
    "df_opera_city_growth_unique = df_city_growth_sorted.drop_duplicates(subset='city', keep='first')\n",
    "\n",
    "# Get top 10 countries with highest predicted growth\n",
    "top_cities_predicted = df_opera_city_growth_unique.head(10)\n",
    "print(top_cities_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f7673ad5-e24a-4277-a639-86068f1db99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 6.3590184769026\n",
      "MSE: 40.43711598958866\n",
      "RMSE: 6.3590184769026\n",
      "R2_Score: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:918: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
      "  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction\n",
    "y_pred_city_lin = lin_city.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate model\n",
    "lin_evaluate_model(y_test_city, y_pred_city_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abbe008-a80f-4c5b-afe4-6a8762e98a91",
   "metadata": {},
   "source": [
    "Logistic Regression Models - let's see if we can get a better predictive model using Logistic regression without countries being grouped first and then try it with grouping countries. In order to run a Logistic regression model, I binned the country_change_from_previous_season by quartiles into categories of Low, Medium, High and Very High so there is a category that is being used as the dependent outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e2120524-767c-4f77-8f52-e3af6cfe4227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "# Independent variables (predictors)\n",
    "X_country = opera[['country population', 'performances_season_by_country', \n",
    "                   'perf_per_10k_ppl_co_pop', 'Year', 'Month', 'Day', \n",
    "                   'Weekday', 'Week_of_Year', 'Days_Since_Start']]\n",
    "\n",
    "# Dependent variable (growth at country level)\n",
    "y_country = opera['country_change_from_previous_season']\n",
    "\n",
    "# Convert continuous growth to categorical labels (Low, Medium, High)\n",
    "q1 = opera['country_change_from_previous_season'].quantile(0.25)\n",
    "q2 = opera['country_change_from_previous_season'].quantile(0.50)\n",
    "q3 = opera['country_change_from_previous_season'].quantile(0.75)\n",
    "\n",
    "bins = [-float('inf'), q1, q2, q3, float('inf')]\n",
    "labels = ['Low', 'Medium', 'High', 'Very High']\n",
    "\n",
    "y_country_classified = pd.cut(y_country, bins=bins, labels=labels)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train_country, y_test_country = train_test_split(X_country, y_country_classified, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data (using the same scaler as the training data)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4938c412-7640-4235-9b2f-4e2f094a126d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "30 fits failed out of a total of 120.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.48131881 0.4958945         nan        nan 0.47912569 0.49402774\n",
      " 0.49402774 0.49401895 0.48260134 0.49559784        nan        nan\n",
      " 0.48188413 0.49525378 0.4953956  0.49534482 0.48267921 0.49678021\n",
      "        nan        nan 0.48265772 0.49579333 0.49584594 0.49582276]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Best F1 Score: 0.4967802102795608\n"
     ]
    }
   ],
   "source": [
    "# Initialize LogisticRegression\n",
    "lr_country = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# Define the hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],  # Regularization strength\n",
    "    'solver': ['liblinear', 'saga'],  # Use 'liblinear' and 'saga' or 'lbfgs' for L1\n",
    "}\n",
    "\n",
    "# Define the custom scoring function (e.g., F1 score)\n",
    "custom_scorer = make_scorer(f1_score, average='weighted')\n",
    "\n",
    "# GridSearchCV with custom scoring\n",
    "grid_search = GridSearchCV(estimator=lr_country, param_grid=param_grid, scoring=custom_scorer, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train_country)\n",
    "\n",
    "# Output the best parameters and the best F1 score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best F1 Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "393ca4ca-eefb-4da8-9548-3b1f366fccb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Country Name predicted_country_growth\n",
      "14885             Germany                Very High\n",
      "30745  Russian Federation                Very High\n",
      "5744        United States                Very High\n",
      "35313              France                Very High\n",
      "35617               Italy                Very High\n",
      "11771      United Kingdom                   Medium\n",
      "14110         Switzerland                   Medium\n",
      "20053             Austria                   Medium\n",
      "10736             Romania                   Medium\n",
      "10433              Poland                   Medium\n"
     ]
    }
   ],
   "source": [
    "# Best parameters found during the grid search\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Create the Logistic Regression model with the best parameters\n",
    "lr_country = LogisticRegression(\n",
    "    C=best_params['C'],\n",
    "    solver=best_params['solver'],\n",
    "    max_iter=10000\n",
    ")\n",
    "\n",
    "# Train the model on scaled data\n",
    "lr_country.fit(X_train_scaled, y_train_country)\n",
    "\n",
    "# Transform the entire country data to scaled values before prediction (using the same scaler)\n",
    "X_country_scaled = scaler.transform(X_country)\n",
    "\n",
    "# Predict growth for the entire country dataset\n",
    "opera['predicted_country_growth'] = lr_country.predict(X_country_scaled)\n",
    "\n",
    "# Sort countries based on predicted growth\n",
    "df_country_growth_sorted = opera[['Country Name', 'predicted_country_growth']].sort_values(by='predicted_country_growth', ascending=False)\n",
    "\n",
    "# Drop duplicates and keep the row with the highest growth for each country\n",
    "df_opera_country_growth_unique = df_country_growth_sorted.drop_duplicates(subset='Country Name', keep='first')\n",
    "\n",
    "# Get top 10 countries with highest predicted growth\n",
    "top_countries_predicted = df_opera_country_growth_unique.head(10)\n",
    "print(top_countries_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b13aae30-1b4f-46d3-93a0-bda830abe562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5205444273240883\n",
      "Precision (macro): 0.49693556228738306\n",
      "Recall (macro): 0.5184874896884587\n"
     ]
    }
   ],
   "source": [
    "#Make a prediction\n",
    "y_pred_country_lr = lr_country.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test_country, y_pred_country_lr)\n",
    "final_results.append(accuracy)\n",
    "evaluate_model(y_test_country, y_pred_country_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c8a9aa03-9849-4ac9-a3a4-794fa77ce5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent variables (predictors)\n",
    "X_country = opera[['country population', 'performances_season_by_country', \n",
    "                   'perf_per_10k_ppl_co_pop', 'Year', 'Month', 'Day', \n",
    "                   'Weekday', 'Week_of_Year', 'Days_Since_Start']]\n",
    "\n",
    "# Dependent variable (growth at country level)\n",
    "y_country = opera['country_change_from_previous_season']\n",
    "\n",
    "# Convert continuous growth to categorical labels (Low, Medium, High)\n",
    "q1 = opera['country_change_from_previous_season'].quantile(0.25)\n",
    "q2 = opera['country_change_from_previous_season'].quantile(0.50)\n",
    "q3 = opera['country_change_from_previous_season'].quantile(0.75)\n",
    "\n",
    "bins = [-float('inf'), q1, q2, q3, float('inf')]\n",
    "labels = ['Low', 'Medium', 'High', 'Very High']\n",
    "\n",
    "y_country_classified = pd.cut(y_country, bins=bins, labels=labels)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train_country, y_test_country = train_test_split(X_country, y_country_classified, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data (using the same scaler as the training data)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e399022d-e0dc-47ca-a7e2-48909fe1a998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LogisticRegression\n",
    "lr_country = LogisticRegression(max_iter=10000, multi_class='ovr')\n",
    "\n",
    "# Define the hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],  # Regularization strength\n",
    "    'solver': ['liblinear', 'saga'],  # Use 'liblinear' and 'saga' or 'lbfgs' for L1\n",
    "}\n",
    "\n",
    "# Define the custom scoring function (e.g., F1 score)\n",
    "custom_scorer = make_scorer(f1_score, average='weighted')\n",
    "\n",
    "# GridSearchCV with custom scoring\n",
    "grid_search = GridSearchCV(estimator=lr_country, param_grid=param_grid, scoring=custom_scorer, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train_country)\n",
    "\n",
    "# Output the best parameters and the best F1 score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best F1 Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8812b3-16fb-4201-be26-ccdbe5eeb4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Country\n",
    "country_groups = opera.groupby('Country Name')\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Model for country growth prediction\n",
    "lin_country = LinearRegression()\n",
    "\n",
    "# Store the predicted values in a DataFrame\n",
    "predicted_growth_values = pd.Series(index=opera.index)  # Create an empty Series to store predictions\n",
    "\n",
    "# Loop through each country group to train and predict separately\n",
    "for country_name, group in country_groups:\n",
    "    # If the group has more than one sample, split and train\n",
    "    if len(group) > 1:\n",
    "        # Extract the features and target for this country group\n",
    "        X_group = group[['country population', 'performances_season_by_country', 'perf_per_10k_ppl_co_pop', \n",
    "                         'city population', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', 'Year', 'Month', 'Day', \n",
    "                         'Weekday', 'Week_of_Year', 'Days_Since_Start']]\n",
    "        y_group = group['country_change_from_previous_season']\n",
    "\n",
    "        # Split data into train and test sets (80% train, 20% test)\n",
    "        X_train, X_test, y_train_country, y_test_country = train_test_split(X_group, y_group, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Scale the training data\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "        # Train the model on the training data\n",
    "        lin_country.fit(X_train_scaled, y_train_country)\n",
    "\n",
    "        # Scale the test data using the same scaler\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # Make predictions for the test set\n",
    "        predictions = lin_country.predict(X_test_scaled)\n",
    "\n",
    "        # Assign predictions to the correct indices in the original DataFrame\n",
    "        predicted_growth_values.loc[X_test.index] = predictions  # Correctly assign predictions to test set rows\n",
    "    else:\n",
    "        # If the group has only one sample, predict directly and append\n",
    "        X_group = group[['country population', 'performances_season_by_country', 'perf_per_10k_ppl_co_pop', \n",
    "                         'city population', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', 'Year', 'Month', 'Day', \n",
    "                         'Weekday', 'Week_of_Year', 'Days_Since_Start']]\n",
    "        y_group = group['country_change_from_previous_season']\n",
    "        \n",
    "        # Scale the data for this group\n",
    "        X_scaled = scaler.fit_transform(X_group)\n",
    "\n",
    "        # Train the model\n",
    "        lin_country.fit(X_scaled, y_group)\n",
    "\n",
    "        # Make predictions for this group\n",
    "        predictions = lin_country.predict(X_scaled)\n",
    "        \n",
    "        # Assign predictions to the correct indices in the original DataFrame\n",
    "        predicted_growth_values.loc[group.index] = predictions  # Correctly assign predictions to the original rows\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
