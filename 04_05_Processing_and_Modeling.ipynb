{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddb80c4b-3cf8-459b-b44e-f8bf5911030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import __version__ as sklearn_version\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de73d6eb-0f44-4958-bd4e-b102a5e698e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>iso</th>\n",
       "      <th>city</th>\n",
       "      <th>composer</th>\n",
       "      <th>db</th>\n",
       "      <th>dd</th>\n",
       "      <th>nat</th>\n",
       "      <th>mf</th>\n",
       "      <th>work</th>\n",
       "      <th>worknat</th>\n",
       "      <th>...</th>\n",
       "      <th>performances_season_by_city</th>\n",
       "      <th>perf_per_1k_ppl_city_pop</th>\n",
       "      <th>opera_by_composer</th>\n",
       "      <th>performances_season_by_country_total</th>\n",
       "      <th>performances_season_by_city_total</th>\n",
       "      <th>perf_total_per_1k_city_pop</th>\n",
       "      <th>perf_total_per_10k_co_pop</th>\n",
       "      <th>Season Year</th>\n",
       "      <th>country_change_from_previous_season</th>\n",
       "      <th>city_change_from_previous_season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1213</td>\n",
       "      <td>al</td>\n",
       "      <td>Tirana</td>\n",
       "      <td>Lortzing</td>\n",
       "      <td>1801</td>\n",
       "      <td>1851</td>\n",
       "      <td>de</td>\n",
       "      <td>m</td>\n",
       "      <td>Ali Pascha von Janina</td>\n",
       "      <td>de</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.021506</td>\n",
       "      <td>Ali Pascha von Janina by Lor</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>0.262847</td>\n",
       "      <td>0.385301</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1213</td>\n",
       "      <td>al</td>\n",
       "      <td>Tirana</td>\n",
       "      <td>Mozart</td>\n",
       "      <td>1756</td>\n",
       "      <td>1791</td>\n",
       "      <td>at</td>\n",
       "      <td>m</td>\n",
       "      <td>Don Giovanni</td>\n",
       "      <td>it</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.021506</td>\n",
       "      <td>Don Giovanni by Moz</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>0.262847</td>\n",
       "      <td>0.385301</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1213</td>\n",
       "      <td>al</td>\n",
       "      <td>Tirana</td>\n",
       "      <td>Puccini</td>\n",
       "      <td>1858</td>\n",
       "      <td>1924</td>\n",
       "      <td>it</td>\n",
       "      <td>m</td>\n",
       "      <td>Tosca</td>\n",
       "      <td>it</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.021506</td>\n",
       "      <td>Tosca by Puc</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>0.262847</td>\n",
       "      <td>0.385301</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1213</td>\n",
       "      <td>am</td>\n",
       "      <td>Yerevan</td>\n",
       "      <td>Spendiaryan</td>\n",
       "      <td>1871</td>\n",
       "      <td>1928</td>\n",
       "      <td>am</td>\n",
       "      <td>m</td>\n",
       "      <td>Almast</td>\n",
       "      <td>am</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004573</td>\n",
       "      <td>Almast by Spe</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>0.101510</td>\n",
       "      <td>0.371147</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1213</td>\n",
       "      <td>am</td>\n",
       "      <td>Yerevan</td>\n",
       "      <td>Tigranian</td>\n",
       "      <td>1879</td>\n",
       "      <td>1950</td>\n",
       "      <td>am</td>\n",
       "      <td>m</td>\n",
       "      <td>Anoush</td>\n",
       "      <td>am</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004573</td>\n",
       "      <td>Anoush by Tig</td>\n",
       "      <td>111</td>\n",
       "      <td>111</td>\n",
       "      <td>0.101510</td>\n",
       "      <td>0.371147</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   season iso     city     composer    db    dd nat mf                   work  \\\n",
       "0    1213  al   Tirana     Lortzing  1801  1851  de  m  Ali Pascha von Janina   \n",
       "1    1213  al   Tirana       Mozart  1756  1791  at  m           Don Giovanni   \n",
       "2    1213  al   Tirana      Puccini  1858  1924  it  m                  Tosca   \n",
       "3    1213  am  Yerevan  Spendiaryan  1871  1928  am  m                 Almast   \n",
       "4    1213  am  Yerevan    Tigranian  1879  1950  am  m                 Anoush   \n",
       "\n",
       "  worknat  ... performances_season_by_city perf_per_1k_ppl_city_pop  \\\n",
       "0      de  ...                           9                 0.021506   \n",
       "1      it  ...                           9                 0.021506   \n",
       "2      it  ...                           9                 0.021506   \n",
       "3      am  ...                           5                 0.004573   \n",
       "4      am  ...                           5                 0.004573   \n",
       "\n",
       "              opera_by_composer performances_season_by_country_total  \\\n",
       "0  Ali Pascha von Janina by Lor                                  110   \n",
       "1           Don Giovanni by Moz                                  110   \n",
       "2                  Tosca by Puc                                  110   \n",
       "3                 Almast by Spe                                  111   \n",
       "4                 Anoush by Tig                                  111   \n",
       "\n",
       "   performances_season_by_city_total  perf_total_per_1k_city_pop  \\\n",
       "0                                110                    0.262847   \n",
       "1                                110                    0.262847   \n",
       "2                                110                    0.262847   \n",
       "3                                111                    0.101510   \n",
       "4                                111                    0.101510   \n",
       "\n",
       "  perf_total_per_10k_co_pop Season Year  country_change_from_previous_season  \\\n",
       "0                  0.385301  2013-01-01                                  NaN   \n",
       "1                  0.385301  2013-01-01                                  NaN   \n",
       "2                  0.385301  2013-01-01                                  NaN   \n",
       "3                  0.371147  2013-01-01                                  NaN   \n",
       "4                  0.371147  2013-01-01                                  NaN   \n",
       "\n",
       "   city_change_from_previous_season  \n",
       "0                               NaN  \n",
       "1                               NaN  \n",
       "2                               NaN  \n",
       "3                               NaN  \n",
       "4                               NaN  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opera = pd.read_excel('/Users/angelique/Documents/GitHub/New_Opera_Company_Capstone/Excel and CSV Files/opera_4.xlsx')\n",
    "opera.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c10859f5-efe4-4080-85cf-0d84b8c6035b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['season', 'iso', 'city', 'composer', 'db', 'dd', 'nat', 'mf', 'work',\n",
       "       'worknat', 'type', 'start date', 'performances', 'Country Name',\n",
       "       'city population', 'country population', 'continent', 'sub-region',\n",
       "       'performances_season_by_country', 'perf_per_10k_ppl_co_pop',\n",
       "       'performances_season_by_city', 'perf_per_1k_ppl_city_pop',\n",
       "       'opera_by_composer', 'performances_season_by_country_total',\n",
       "       'performances_season_by_city_total', 'perf_total_per_1k_city_pop',\n",
       "       'perf_total_per_10k_co_pop', 'Season Year',\n",
       "       'country_change_from_previous_season',\n",
       "       'city_change_from_previous_season'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opera.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90bcf431-c363-47ae-9b09-3781e993e7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "season                                           int64\n",
       "iso                                             object\n",
       "city                                            object\n",
       "composer                                        object\n",
       "db                                              object\n",
       "dd                                              object\n",
       "nat                                             object\n",
       "mf                                              object\n",
       "work                                            object\n",
       "worknat                                         object\n",
       "type                                            object\n",
       "start date                              datetime64[ns]\n",
       "performances                                     int64\n",
       "Country Name                                    object\n",
       "city population                                  int64\n",
       "country population                             float64\n",
       "continent                                       object\n",
       "sub-region                                      object\n",
       "performances_season_by_country                   int64\n",
       "perf_per_10k_ppl_co_pop                        float64\n",
       "performances_season_by_city                      int64\n",
       "perf_per_1k_ppl_city_pop                       float64\n",
       "opera_by_composer                               object\n",
       "performances_season_by_country_total             int64\n",
       "performances_season_by_city_total                int64\n",
       "perf_total_per_1k_city_pop                     float64\n",
       "perf_total_per_10k_co_pop                      float64\n",
       "Season Year                             datetime64[ns]\n",
       "country_change_from_previous_season            float64\n",
       "city_change_from_previous_season               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opera.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7c8b24f-6f63-4ba3-8431-b2274f1be84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>iso</th>\n",
       "      <th>city</th>\n",
       "      <th>composer</th>\n",
       "      <th>db</th>\n",
       "      <th>dd</th>\n",
       "      <th>nat</th>\n",
       "      <th>mf</th>\n",
       "      <th>work</th>\n",
       "      <th>worknat</th>\n",
       "      <th>...</th>\n",
       "      <th>perf_total_per_10k_co_pop</th>\n",
       "      <th>Season Year</th>\n",
       "      <th>country_change_from_previous_season</th>\n",
       "      <th>city_change_from_previous_season</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Week_of_Year</th>\n",
       "      <th>Days_Since_Start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1213</td>\n",
       "      <td>al</td>\n",
       "      <td>Tirana</td>\n",
       "      <td>Lortzing</td>\n",
       "      <td>1801</td>\n",
       "      <td>1851</td>\n",
       "      <td>de</td>\n",
       "      <td>m</td>\n",
       "      <td>Ali Pascha von Janina</td>\n",
       "      <td>de</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385301</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1213</td>\n",
       "      <td>al</td>\n",
       "      <td>Tirana</td>\n",
       "      <td>Mozart</td>\n",
       "      <td>1756</td>\n",
       "      <td>1791</td>\n",
       "      <td>at</td>\n",
       "      <td>m</td>\n",
       "      <td>Don Giovanni</td>\n",
       "      <td>it</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385301</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1213</td>\n",
       "      <td>al</td>\n",
       "      <td>Tirana</td>\n",
       "      <td>Puccini</td>\n",
       "      <td>1858</td>\n",
       "      <td>1924</td>\n",
       "      <td>it</td>\n",
       "      <td>m</td>\n",
       "      <td>Tosca</td>\n",
       "      <td>it</td>\n",
       "      <td>...</td>\n",
       "      <td>0.385301</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1213</td>\n",
       "      <td>am</td>\n",
       "      <td>Yerevan</td>\n",
       "      <td>Spendiaryan</td>\n",
       "      <td>1871</td>\n",
       "      <td>1928</td>\n",
       "      <td>am</td>\n",
       "      <td>m</td>\n",
       "      <td>Almast</td>\n",
       "      <td>am</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371147</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1213</td>\n",
       "      <td>am</td>\n",
       "      <td>Yerevan</td>\n",
       "      <td>Tigranian</td>\n",
       "      <td>1879</td>\n",
       "      <td>1950</td>\n",
       "      <td>am</td>\n",
       "      <td>m</td>\n",
       "      <td>Anoush</td>\n",
       "      <td>am</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371147</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   season iso     city     composer    db    dd nat mf                   work  \\\n",
       "0    1213  al   Tirana     Lortzing  1801  1851  de  m  Ali Pascha von Janina   \n",
       "1    1213  al   Tirana       Mozart  1756  1791  at  m           Don Giovanni   \n",
       "2    1213  al   Tirana      Puccini  1858  1924  it  m                  Tosca   \n",
       "3    1213  am  Yerevan  Spendiaryan  1871  1928  am  m                 Almast   \n",
       "4    1213  am  Yerevan    Tigranian  1879  1950  am  m                 Anoush   \n",
       "\n",
       "  worknat  ... perf_total_per_10k_co_pop Season Year  \\\n",
       "0      de  ...                  0.385301  2013-01-01   \n",
       "1      it  ...                  0.385301  2013-01-01   \n",
       "2      it  ...                  0.385301  2013-01-01   \n",
       "3      am  ...                  0.371147  2013-01-01   \n",
       "4      am  ...                  0.371147  2013-01-01   \n",
       "\n",
       "   country_change_from_previous_season city_change_from_previous_season  Year  \\\n",
       "0                                  NaN                              NaN  2013   \n",
       "1                                  NaN                              NaN  2013   \n",
       "2                                  NaN                              NaN  2013   \n",
       "3                                  NaN                              NaN  2013   \n",
       "4                                  NaN                              NaN  2013   \n",
       "\n",
       "   Month Day Weekday  Week_of_Year  Days_Since_Start  \n",
       "0      3  23       5            12               273  \n",
       "1      5  18       5            20               329  \n",
       "2      2  13       2             7               235  \n",
       "3      7  11       3            28               383  \n",
       "4      5  11       5            19               322  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opera['Year'] = opera['start date'].dt.year\n",
    "opera['Month'] = opera['start date'].dt.month\n",
    "opera['Day'] = opera['start date'].dt.day\n",
    "opera['Weekday'] = opera['start date'].dt.weekday\n",
    "opera['Week_of_Year'] = opera['start date'].dt.isocalendar().week\n",
    "opera['Days_Since_Start'] = (opera['start date'] - opera['start date'].min()).dt.days\n",
    "opera.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2350bdd4-f0d1-4c27-887d-c53a313a1587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['season', 'iso', 'city', 'composer', 'db', 'dd', 'nat', 'mf', 'work',\n",
       "       'worknat', 'type', 'start date', 'performances', 'Country Name',\n",
       "       'city population', 'country population', 'continent', 'sub-region',\n",
       "       'performances_season_by_country', 'perf_per_10k_ppl_co_pop',\n",
       "       'performances_season_by_city', 'perf_per_1k_ppl_city_pop',\n",
       "       'opera_by_composer', 'performances_season_by_country_total',\n",
       "       'performances_season_by_city_total', 'perf_total_per_1k_city_pop',\n",
       "       'perf_total_per_10k_co_pop', 'Season Year',\n",
       "       'country_change_from_previous_season',\n",
       "       'city_change_from_previous_season', 'Year', 'Month', 'Day', 'Weekday',\n",
       "       'Week_of_Year', 'Days_Since_Start'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opera.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d4a4b96-f4f9-4e40-bbac-3252164e0ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               city iso  city_change_from_previous_season\n",
      "748          Moscow  ru                           27911.0\n",
      "1216     Washington  us                           16128.0\n",
      "1062  St Petersburg  ru                            9681.0\n",
      "51        Arlington  us                            9648.0\n",
      "263        Columbus  us                            3549.0\n",
      "759         München  de                            3381.0\n",
      "931        Richmond  us                            3042.0\n",
      "846           Paris  fr                            2971.0\n",
      "868    Philadelphia  us                            2916.0\n",
      "327      Dusseldorf  de                            1677.0\n",
      "315         Dresden  de                            1674.0\n",
      "892     Portland OR  us                            1539.0\n",
      "62          Atlanta  us                            1312.0\n",
      "295          Denver  us                            1168.0\n",
      "371         Firenze  it                            1163.0\n",
      "1204       Voronezh  ru                             979.0\n",
      "290          Dayton  us                             968.0\n",
      "538         Jackson  us                             900.0\n",
      "642            Linz  at                             866.0\n",
      "687          Madrid  es                             861.0\n",
      "460           Halle  de                             820.0\n",
      "383       Frankfurt  de                             817.0\n",
      "95        Barcelona  es                             765.0\n",
      "869         Phoenix  us                             720.0\n",
      "605       Lancaster  us                             720.0\n"
     ]
    }
   ],
   "source": [
    "# Rank cities based on the sum of growth in performances\n",
    "opera_city_growth = opera[['city', 'city_change_from_previous_season', 'iso']]\n",
    "\n",
    "# Group by city and iso, and sum the 'city_change_from_previous_season' for each city\n",
    "city_growth_sum = opera_city_growth.groupby(['city', 'iso'], as_index=False)['city_change_from_previous_season'].sum()\n",
    "\n",
    "# Sort cities by total growth (sum), highest growth first\n",
    "city_growth_sorted = city_growth_sum.sort_values(by='city_change_from_previous_season', ascending=False)\n",
    "\n",
    "# Drop duplicates and keep the row with the highest growth for each city\n",
    "opera_city_growth_unique = city_growth_sorted.drop_duplicates(subset='city', keep='first')\n",
    "\n",
    "# Get the top cities with the highest total growth\n",
    "top_cities = opera_city_growth_unique.head(25)  # Top 10 cities with the highest total growth\n",
    "\n",
    "# Print the result\n",
    "print(top_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0ede498-2ab2-4104-aa35-10cd12d0561d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Country Name iso  country_change_from_previous_season\n",
      "58  Russian Federation  ru                             194425.0\n",
      "34               Italy  it                              87941.0\n",
      "65              Sweden  se                               6459.0\n",
      "55              Poland  pl                               5653.0\n",
      "64               Spain  es                               3115.0\n",
      "50         Netherlands  nl                               2892.0\n",
      "35               Japan  jp                                631.0\n",
      "39              Latvia  lv                                529.0\n",
      "23             Estonia  ee                                517.0\n",
      "62            Slovenia  si                                509.0\n",
      "6              Belarus  by                                450.0\n",
      "73          Uzbekistan  uz                                450.0\n",
      "2              Armenia  am                                442.0\n",
      "13               China  cn                                396.0\n",
      "59              Serbia  rs                                372.0\n",
      "1            Argentina  ar                                288.0\n",
      "37  Korea, Republic of  kr                                211.0\n",
      "49            Mongolia  mn                                180.0\n",
      "32             Ireland  ie                                177.0\n",
      "20             Denmark  dk                                165.0\n",
      "0              Albania  al                                115.0\n",
      "26             Georgia  ge                                111.0\n",
      "46              Mexico  mx                                 91.0\n",
      "51         New Zealand  nz                                 73.0\n",
      "36          Kazakhstan  kz                                 66.0\n"
     ]
    }
   ],
   "source": [
    "# Rank countries based on the sum of growth in performances\n",
    "opera_country_growth = opera[['Country Name', 'country_change_from_previous_season', 'iso']]\n",
    "\n",
    "# Group by country and iso, and sum the 'country_change_from_previous_season' for each country\n",
    "country_growth_sum = opera_country_growth.groupby(['Country Name', 'iso'], as_index=False)['country_change_from_previous_season'].sum()\n",
    "\n",
    "# Sort countries by total growth (sum), highest growth first\n",
    "country_growth_sorted = country_growth_sum.sort_values(by='country_change_from_previous_season', ascending=False)\n",
    "\n",
    "# Drop duplicates and keep the row with the highest growth for each city\n",
    "opera_country_growth_unique = country_growth_sorted.drop_duplicates(subset='Country Name', keep='first')\n",
    "\n",
    "# Get the top cities with the highest total growth\n",
    "top_countries = opera_country_growth_unique.head(25)  # Top 10 cities with the highest total growth\n",
    "\n",
    "# Print the result\n",
    "print(top_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ff10f9a-ffbd-44c6-907c-e6de178876f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "season                                     0\n",
      "iso                                        0\n",
      "city                                       0\n",
      "composer                                   5\n",
      "db                                       227\n",
      "dd                                      3593\n",
      "nat                                       11\n",
      "mf                                         0\n",
      "work                                       5\n",
      "worknat                                 1548\n",
      "type                                       0\n",
      "start date                                 0\n",
      "performances                               0\n",
      "Country Name                               0\n",
      "city population                            0\n",
      "country population                         0\n",
      "continent                                  0\n",
      "sub-region                                 0\n",
      "performances_season_by_country             0\n",
      "perf_per_10k_ppl_co_pop                    0\n",
      "performances_season_by_city                0\n",
      "perf_per_1k_ppl_city_pop                   0\n",
      "opera_by_composer                          5\n",
      "performances_season_by_country_total       0\n",
      "performances_season_by_city_total          0\n",
      "perf_total_per_1k_city_pop                 0\n",
      "perf_total_per_10k_co_pop                  0\n",
      "Season Year                                0\n",
      "country_change_from_previous_season     6559\n",
      "city_change_from_previous_season        7191\n",
      "Year                                       0\n",
      "Month                                      0\n",
      "Day                                        0\n",
      "Weekday                                    0\n",
      "Week_of_Year                               0\n",
      "Days_Since_Start                           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_count_per_column = opera.isna().sum()\n",
    "print(nan_count_per_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "871012d9-d922-4737-b9bf-e1fafd36a3f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infinity counts per numeric column:\n",
      "season                                  0\n",
      "performances                            0\n",
      "city population                         0\n",
      "country population                      0\n",
      "performances_season_by_country          0\n",
      "perf_per_10k_ppl_co_pop                 0\n",
      "performances_season_by_city             0\n",
      "perf_per_1k_ppl_city_pop                0\n",
      "performances_season_by_country_total    0\n",
      "performances_season_by_city_total       0\n",
      "perf_total_per_1k_city_pop              0\n",
      "perf_total_per_10k_co_pop               0\n",
      "country_change_from_previous_season     0\n",
      "city_change_from_previous_season        0\n",
      "Year                                    0\n",
      "Month                                   0\n",
      "Day                                     0\n",
      "Weekday                                 0\n",
      "Week_of_Year                            0\n",
      "Days_Since_Start                        0\n",
      "dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Select only numeric columns\n",
    "numeric_columns = opera.select_dtypes(include=[np.number])\n",
    "\n",
    "# Step 2: Check for infinity values in the numeric columns\n",
    "infinity_counts = np.isinf(numeric_columns).sum()\n",
    "\n",
    "# Step 3: Print the count of infinity values per numeric column\n",
    "print(\"Infinity counts per numeric column:\")\n",
    "print(infinity_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8eb3106-b2da-4d65-ad7b-af10c2fa55dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the condition for selecting rows\n",
    "condition = (opera['iso'] == 'cu') & (opera['city'] == 'La Habana')\n",
    "\n",
    "# Apply fillna() to the 'country_change_from_previous_season' column for the selected rows\n",
    "opera.loc[condition, 'country_change_from_previous_season'] = opera.loc[\n",
    "    condition, 'country_change_from_previous_season'\n",
    "].fillna(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1813f5e-8003-4f6d-a622-b0d1cac94071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       season iso       city composer    db    dd nat mf          work  \\\n",
      "27083    1617  cu  La Habana   Mozart  1756  1791  at  m  Don Giovanni   \n",
      "\n",
      "      worknat  ... perf_total_per_10k_co_pop Season Year  \\\n",
      "27083      it  ...                  0.001783  2017-01-01   \n",
      "\n",
      "       country_change_from_previous_season city_change_from_previous_season  \\\n",
      "27083                                  2.0                              NaN   \n",
      "\n",
      "       Year  Month Day Weekday  Week_of_Year  Days_Since_Start  \n",
      "27083  2016     12  17       5            50              1638  \n",
      "\n",
      "[1 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display rows where 'iso' is 'cu' and 'city' is 'La Habana'\n",
    "print(opera[(opera['iso'] == 'cu') & (opera['city'] == 'La Habana')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "167720f7-981b-4af6-9164-8d5fb7663595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of country_missing: 6558\n",
      "Length of predicted values: 6558\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Identify rows with missing values in 'country_change_from_previous_season'\n",
    "country_missing = opera[opera['country_change_from_previous_season'].isna()]\n",
    "\n",
    "# Step 2: Use rows without missing values to train the model\n",
    "country_not_missing = opera.dropna(subset=['country_change_from_previous_season'])\n",
    "\n",
    "# Separate features (X) and target (y) for rows without missing values\n",
    "X_no_missing = country_not_missing[['city population', 'country population', 'performances_season_by_country', \n",
    "                                    'perf_per_10k_ppl_co_pop', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', \n",
    "                                    'Year']]\n",
    "y_no_missing = country_not_missing['country_change_from_previous_season']\n",
    "\n",
    "# Step 3: Train the Linear Regression Model for each iso\n",
    "predicted_values = []\n",
    "\n",
    "# Group the data by 'iso' and perform the prediction for each group\n",
    "for iso_code, group in country_not_missing.groupby('iso'):\n",
    "    # Separate the group into features (X) and target (y)\n",
    "    X_group = group[['city population', 'country population', 'performances_season_by_country', \n",
    "                     'perf_per_10k_ppl_co_pop', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', 'Year']]\n",
    "    y_group = group['country_change_from_previous_season']\n",
    "    \n",
    "    # Train the linear regression model for this specific iso code\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_group, y_group)\n",
    "    \n",
    "    # Get the rows for this iso code that have missing values\n",
    "    missing_group = country_missing[country_missing['iso'] == iso_code]\n",
    "    \n",
    "    # If there are any missing values for this iso, predict them\n",
    "    if not missing_group.empty:\n",
    "        X_missing = missing_group[['city population', 'country population', 'performances_season_by_country', \n",
    "                                  'perf_per_10k_ppl_co_pop', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', 'Year']]\n",
    "        \n",
    "        # Predict the missing values\n",
    "        predictions = model.predict(X_missing)\n",
    "        \n",
    "        # Store the predicted values and add to the list\n",
    "        predicted_values.extend(predictions)\n",
    "\n",
    "# Step 4: Check the lengths to confirm they match\n",
    "print(f\"Length of country_missing: {len(country_missing)}\")\n",
    "print(f\"Length of predicted values: {len(predicted_values)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52762436-b7f0-4495-af25-82e923e5b809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       season iso     city        composer    db    dd nat mf  \\\n",
      "0        1213  al   Tirana        Lortzing  1801  1851  de  m   \n",
      "1        1213  al   Tirana          Mozart  1756  1791  at  m   \n",
      "2        1213  al   Tirana         Puccini  1858  1924  it  m   \n",
      "3        1213  am  Yerevan     Spendiaryan  1871  1928  am  m   \n",
      "4        1213  am  Yerevan       Tigranian  1879  1950  am  m   \n",
      "...       ...  ..      ...             ...   ...   ...  .. ..   \n",
      "10091    1314  kz   Astana           Verdi  1813  1901  it  m   \n",
      "10240    1314  mo    Macau          Mozart  1756  1791  at  m   \n",
      "10241    1314  mo    Macau           Verdi  1813  1901  it  m   \n",
      "10242    1314  mo    Macau           Verdi  1813  1901  it  m   \n",
      "10243    1314  mo    Macau  Wagner,Richard  1813  1883  de  m   \n",
      "\n",
      "                        work worknat  ... perf_total_per_10k_co_pop  \\\n",
      "0      Ali Pascha von Janina      de  ...                  0.385301   \n",
      "1               Don Giovanni      it  ...                  0.385301   \n",
      "2                      Tosca      it  ...                  0.385301   \n",
      "3                     Almast      am  ...                  0.371147   \n",
      "4                     Anoush      am  ...                  0.371147   \n",
      "...                      ...     ...  ...                       ...   \n",
      "10091                 Attila      it  ...                  0.116293   \n",
      "10240  Bastien und Bastienne      de  ...                  0.452592   \n",
      "10241                   Aida      it  ...                  0.452592   \n",
      "10242                Requiem      it  ...                  0.452592   \n",
      "10243          Das Rheingold      de  ...                  0.452592   \n",
      "\n",
      "      Season Year  country_change_from_previous_season  \\\n",
      "0      2013-01-01                             2.230995   \n",
      "1      2013-01-01                             2.230995   \n",
      "2      2013-01-01                             2.230995   \n",
      "3      2013-01-01                             0.000000   \n",
      "4      2013-01-01                             0.000000   \n",
      "...           ...                                  ...   \n",
      "10091  2014-01-01                             5.547862   \n",
      "10240  2014-01-01                             6.592633   \n",
      "10241  2014-01-01                             5.547862   \n",
      "10242  2014-01-01                             6.592633   \n",
      "10243  2014-01-01                             6.592633   \n",
      "\n",
      "      city_change_from_previous_season  Year  Month Day Weekday  Week_of_Year  \\\n",
      "0                                  NaN  2013      3  23       5            12   \n",
      "1                                  NaN  2013      5  18       5            20   \n",
      "2                                  NaN  2013      2  13       2             7   \n",
      "3                                  NaN  2013      7  11       3            28   \n",
      "4                                  NaN  2013      5  11       5            19   \n",
      "...                                ...   ...    ...  ..     ...           ...   \n",
      "10091                              NaN  2013     12  16       0            51   \n",
      "10240                              NaN  2013     10  13       6            41   \n",
      "10241                              NaN  2013     10  11       4            41   \n",
      "10242                              NaN  2013     10   5       5            40   \n",
      "10243                              NaN  2013     10   2       2            40   \n",
      "\n",
      "       Days_Since_Start  \n",
      "0                   273  \n",
      "1                   329  \n",
      "2                   235  \n",
      "3                   383  \n",
      "4                   322  \n",
      "...                 ...  \n",
      "10091               541  \n",
      "10240               477  \n",
      "10241               475  \n",
      "10242               469  \n",
      "10243               466  \n",
      "\n",
      "[6558 rows x 36 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v8/j1kjtws546j8drwljwyklgrm0000gn/T/ipykernel_6184/1160055947.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  country_missing['country_change_from_previous_season'] = predicted_values\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Assign the predicted values to the original DataFrame\n",
    "country_missing['country_change_from_previous_season'] = predicted_values\n",
    "\n",
    "# Print the updated dataframe with predicted values\n",
    "print(country_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6a25337-ec61-40b6-921c-f715a652acd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   season iso     city     composer    db    dd nat mf                   work  \\\n",
      "0    1213  al   Tirana     Lortzing  1801  1851  de  m  Ali Pascha von Janina   \n",
      "1    1213  al   Tirana       Mozart  1756  1791  at  m           Don Giovanni   \n",
      "2    1213  al   Tirana      Puccini  1858  1924  it  m                  Tosca   \n",
      "3    1213  am  Yerevan  Spendiaryan  1871  1928  am  m                 Almast   \n",
      "4    1213  am  Yerevan    Tigranian  1879  1950  am  m                 Anoush   \n",
      "\n",
      "  worknat  ... perf_total_per_10k_co_pop Season Year  \\\n",
      "0      de  ...                  0.385301  2013-01-01   \n",
      "1      it  ...                  0.385301  2013-01-01   \n",
      "2      it  ...                  0.385301  2013-01-01   \n",
      "3      am  ...                  0.371147  2013-01-01   \n",
      "4      am  ...                  0.371147  2013-01-01   \n",
      "\n",
      "   country_change_from_previous_season city_change_from_previous_season  Year  \\\n",
      "0                             2.230995                              NaN  2013   \n",
      "1                             2.230995                              NaN  2013   \n",
      "2                             2.230995                              NaN  2013   \n",
      "3                             0.000000                              NaN  2013   \n",
      "4                             0.000000                              NaN  2013   \n",
      "\n",
      "   Month Day Weekday  Week_of_Year  Days_Since_Start  \n",
      "0      3  23       5            12               273  \n",
      "1      5  18       5            20               329  \n",
      "2      2  13       2             7               235  \n",
      "3      7  11       3            28               383  \n",
      "4      5  11       5            19               322  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Fill the missing values with the predicted values\n",
    "opera.loc[opera['country_change_from_previous_season'].isna(), 'country_change_from_previous_season'] = predicted_values\n",
    "\n",
    "# Now 'df' has the missing values in 'country_change_from_previous_season' filled\n",
    "print(opera.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73220c2c-1add-40cd-9026-08358551a049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "season                                     0\n",
      "iso                                        0\n",
      "city                                       0\n",
      "composer                                   5\n",
      "db                                       227\n",
      "dd                                      3593\n",
      "nat                                       11\n",
      "mf                                         0\n",
      "work                                       5\n",
      "worknat                                 1548\n",
      "type                                       0\n",
      "start date                                 0\n",
      "performances                               0\n",
      "Country Name                               0\n",
      "city population                            0\n",
      "country population                         0\n",
      "continent                                  0\n",
      "sub-region                                 0\n",
      "performances_season_by_country             0\n",
      "perf_per_10k_ppl_co_pop                    0\n",
      "performances_season_by_city                0\n",
      "perf_per_1k_ppl_city_pop                   0\n",
      "opera_by_composer                          5\n",
      "performances_season_by_country_total       0\n",
      "performances_season_by_city_total          0\n",
      "perf_total_per_1k_city_pop                 0\n",
      "perf_total_per_10k_co_pop                  0\n",
      "Season Year                                0\n",
      "country_change_from_previous_season        0\n",
      "city_change_from_previous_season        7191\n",
      "Year                                       0\n",
      "Month                                      0\n",
      "Day                                        0\n",
      "Weekday                                    0\n",
      "Week_of_Year                               0\n",
      "Days_Since_Start                           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_count_per_column = opera.isna().sum()\n",
    "print(nan_count_per_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "96ff3201-8fd0-4287-9147-37a76e6cfc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the condition for selecting rows\n",
    "condition = (opera['iso'] == 'cu') & (opera['city'] == 'La Habana')\n",
    "\n",
    "# Apply fillna() to the 'country_change_from_previous_season' column for the selected rows\n",
    "opera.loc[condition, 'city_change_from_previous_season'] = opera.loc[\n",
    "    condition, 'city_change_from_previous_season'\n",
    "].fillna(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f06e2fa-ed39-47cf-9960-9d2d70fee194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of city_missing: 7190\n",
      "Length of predicted values: 7190\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Identify rows with missing values in 'city_change_from_previous_season'\n",
    "city_missing = opera[opera['city_change_from_previous_season'].isna()]\n",
    "\n",
    "# Step 2: Use rows without missing values to train the model\n",
    "city_not_missing = opera.dropna(subset=['city_change_from_previous_season'])\n",
    "\n",
    "# Separate features (X) and target (y) for rows without missing values\n",
    "X_no_missing = city_not_missing[['city population', 'country population', 'performances_season_by_country', \n",
    "                                    'perf_per_10k_ppl_co_pop', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', \n",
    "                                    'Year']]\n",
    "y_no_missing = city_not_missing['city_change_from_previous_season']\n",
    "\n",
    "# Step 3: Train the Linear Regression Model for each iso\n",
    "predicted_values = []\n",
    "\n",
    "# Group the data by 'iso' and perform the prediction for each group\n",
    "for iso_code, group in city_not_missing.groupby('iso'):\n",
    "    # Separate the group into features (X) and target (y)\n",
    "    X_group = group[['city population', 'country population', 'performances_season_by_country', \n",
    "                     'perf_per_10k_ppl_co_pop', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', 'Year']]\n",
    "    y_group = group['city_change_from_previous_season']\n",
    "    \n",
    "    # Train the linear regression model for this specific iso code\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_group, y_group)\n",
    "    \n",
    "    # Get the rows for this iso code that have missing values\n",
    "    missing_group = city_missing[city_missing['iso'] == iso_code]\n",
    "    \n",
    "    # If there are any missing values for this iso, predict them\n",
    "    if not missing_group.empty:\n",
    "        X_missing = missing_group[['city population', 'country population', 'performances_season_by_country', \n",
    "                                  'perf_per_10k_ppl_co_pop', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', 'Year']]\n",
    "        \n",
    "        # Predict the missing values\n",
    "        predictions = model.predict(X_missing)\n",
    "        \n",
    "        # Store the predicted values and add to the list\n",
    "        predicted_values.extend(predictions)\n",
    "\n",
    "# Step 4: Check the lengths to confirm they match\n",
    "print(f\"Length of city_missing: {len(city_missing)}\")\n",
    "print(f\"Length of predicted values: {len(predicted_values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "667f508c-09b4-4bc3-820e-0910742924d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   season iso     city     composer    db    dd nat mf                   work  \\\n",
      "0    1213  al   Tirana     Lortzing  1801  1851  de  m  Ali Pascha von Janina   \n",
      "1    1213  al   Tirana       Mozart  1756  1791  at  m           Don Giovanni   \n",
      "2    1213  al   Tirana      Puccini  1858  1924  it  m                  Tosca   \n",
      "3    1213  am  Yerevan  Spendiaryan  1871  1928  am  m                 Almast   \n",
      "4    1213  am  Yerevan    Tigranian  1879  1950  am  m                 Anoush   \n",
      "\n",
      "  worknat  ... perf_total_per_10k_co_pop Season Year  \\\n",
      "0      de  ...                  0.385301  2013-01-01   \n",
      "1      it  ...                  0.385301  2013-01-01   \n",
      "2      it  ...                  0.385301  2013-01-01   \n",
      "3      am  ...                  0.371147  2013-01-01   \n",
      "4      am  ...                  0.371147  2013-01-01   \n",
      "\n",
      "   country_change_from_previous_season city_change_from_previous_season  Year  \\\n",
      "0                             2.230995                         2.230995  2013   \n",
      "1                             2.230995                         2.230995  2013   \n",
      "2                             2.230995                         2.230995  2013   \n",
      "3                             0.000000                         0.000000  2013   \n",
      "4                             0.000000                         0.000000  2013   \n",
      "\n",
      "   Month Day Weekday  Week_of_Year  Days_Since_Start  \n",
      "0      3  23       5            12               273  \n",
      "1      5  18       5            20               329  \n",
      "2      2  13       2             7               235  \n",
      "3      7  11       3            28               383  \n",
      "4      5  11       5            19               322  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Fill the missing values with the predicted values\n",
    "opera.loc[opera['city_change_from_previous_season'].isna(), 'city_change_from_previous_season'] = predicted_values\n",
    "\n",
    "# Now 'df' has the missing values in 'country_change_from_previous_season' filled\n",
    "print(opera.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea45b623-9d09-468a-bc6f-703e7b9d7806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "season                                     0\n",
      "iso                                        0\n",
      "city                                       0\n",
      "composer                                   5\n",
      "db                                       227\n",
      "dd                                      3593\n",
      "nat                                       11\n",
      "mf                                         0\n",
      "work                                       5\n",
      "worknat                                 1548\n",
      "type                                       0\n",
      "start date                                 0\n",
      "performances                               0\n",
      "Country Name                               0\n",
      "city population                            0\n",
      "country population                         0\n",
      "continent                                  0\n",
      "sub-region                                 0\n",
      "performances_season_by_country             0\n",
      "perf_per_10k_ppl_co_pop                    0\n",
      "performances_season_by_city                0\n",
      "perf_per_1k_ppl_city_pop                   0\n",
      "opera_by_composer                          5\n",
      "performances_season_by_country_total       0\n",
      "performances_season_by_city_total          0\n",
      "perf_total_per_1k_city_pop                 0\n",
      "perf_total_per_10k_co_pop                  0\n",
      "Season Year                                0\n",
      "country_change_from_previous_season        0\n",
      "city_change_from_previous_season           0\n",
      "Year                                       0\n",
      "Month                                      0\n",
      "Day                                        0\n",
      "Weekday                                    0\n",
      "Week_of_Year                               0\n",
      "Days_Since_Start                           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "nan_count_per_column = opera.isna().sum()\n",
    "print(nan_count_per_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "84db532b-6de1-448e-8cfc-0325e6b44bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix,recall_score , accuracy_score, precision_score, roc_auc_score\n",
    "\n",
    "#Evaluate the model using accuracy, precision, and recall scores under evaluate_model fuction\n",
    "def evaluate_model(y_test, y_pred):\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(f\"Precision (macro): {precision_score(y_test, y_pred, average='macro')}\")\n",
    "    print(f\"Recall (macro): {recall_score(y_test, y_pred, average='macro')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0009cd90-4f6d-4332-b682-7b17cf7dc1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "#Evaluate the model using mean absolute error, mean standard error, root mean square error and the rsquared score under lin_evaluate_model fuction\n",
    "def lin_evaluate_model(y_test, y_pred):\n",
    "    print(f\"MAE: {mean_absolute_error(y_test, y_pred)}\")\n",
    "    print(f\"MSE: {mean_squared_error(y_test, y_pred)}\")\n",
    "    print(f\"RMSE: {mean_squared_error(y_test, y_pred, squared=False)}\")\n",
    "    print(f\"R2_Score: {r2_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee7efce2-6ce0-41b1-b000-a38544c14b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30630cfc-0559-4f37-994e-f06418e8497d",
   "metadata": {},
   "source": [
    "Linear Regression models - I ran these first without grouping by Country to help the predictive model just as a starting point to see how a linear regression model would perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6f090f37-06ec-4272-8422-605730ecdde8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Country Name  predicted_country_growth\n",
      "263      Australia                 75.180739\n",
      "190        Austria                 72.237065\n",
      "2427       Finland                 63.241543\n",
      "3883       Romania                 59.168818\n",
      "4515      Slovenia                 58.507863\n",
      "16338      Hungary                 58.266885\n",
      "3390     Lithuania                 58.138222\n",
      "3798        Poland                 56.789262\n",
      "4615        Turkey                 47.124328\n",
      "14132  Switzerland                 46.597059\n"
     ]
    }
   ],
   "source": [
    "X_country = opera[['country population', 'performances_season_by_country', 'perf_per_10k_ppl_co_pop',\n",
    "                   'city population', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', 'Year', 'Month', 'Day', \n",
    "                   'Weekday', 'Week_of_Year', 'Days_Since_Start']]\n",
    "\n",
    "# Dependent variable (growth at country level)\n",
    "y_country = opera['country_change_from_previous_season']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train_country, y_test_country = train_test_split(X_country, y_country, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data (using the same scaler as the training data)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Model for country growth prediction\n",
    "lin_country = LinearRegression()\n",
    "\n",
    "# Train the model on scaled data\n",
    "lin_country.fit(X_train_scaled, y_train_country)\n",
    "\n",
    "# Transform the entire country data to scaled values before prediction (using the same scaler)\n",
    "X_country_scaled = scaler.transform(X_country)\n",
    "\n",
    "# Predict growth for the entire country dataset\n",
    "opera['predicted_country_growth'] = lin_country.predict(X_country_scaled)\n",
    "\n",
    "# Sort countries based on predicted growth\n",
    "df_country_growth_sorted = opera[['Country Name', 'predicted_country_growth']].sort_values(by='predicted_country_growth', ascending=False)\n",
    "\n",
    "# Drop duplicates and keep the row with the highest growth for each city\n",
    "df_opera_country_growth_unique = df_country_growth_sorted.drop_duplicates(subset='Country Name', keep='first')\n",
    "\n",
    "# Get top 10 countries with highest predicted growth\n",
    "top_countries_predicted = df_opera_country_growth_unique.head(10)\n",
    "print(top_countries_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3979f988-f03f-4459-90e3-0e3c6fa06c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 147.3972739647199\n",
      "MSE: 41254.4963747648\n",
      "RMSE: 203.1120291237444\n",
      "R2_Score: 0.038655174243710566\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction\n",
    "y_pred_country_lin = lin_country.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate model\n",
    "lin_evaluate_model(y_test_country, y_pred_country_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2ea2c806-91e9-48e7-879e-851a02cd9d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      iso         city  predicted_city_growth\n",
      "263    au       Sydney              75.180739\n",
      "190    at       Vienna              72.237065\n",
      "2427   fi     Helsinki              63.241543\n",
      "3883   ro  Cluj-Napoca              59.168818\n",
      "4515   si      Maribor              58.507863\n",
      "16338  hu     Budapest              58.266885\n",
      "3390   lt      Vilnius              58.138222\n",
      "3798   pl      Wroclaw              56.789262\n",
      "10736  ro    Timisoara              55.113396\n",
      "10113  lt       Kaunas              53.492196\n"
     ]
    }
   ],
   "source": [
    "# Independent variables (predictors)\n",
    "X_city = opera[['country population', 'performances_season_by_country', 'perf_per_10k_ppl_co_pop',\n",
    "                   'city population', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', 'Year', 'Month', 'Day', \n",
    "                   'Weekday', 'Week_of_Year', 'Days_Since_Start']]\n",
    "\n",
    "# Dependent variable (growth at city level)\n",
    "y_city = opera['city_change_from_previous_season']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train_city, y_test_city = train_test_split(X_city, y_city, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data (using the same scaler as the training data)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Model for city growth prediction\n",
    "lin_city = LinearRegression()\n",
    "\n",
    "# Train the model on scaled data\n",
    "lin_city.fit(X_train_scaled, y_train_city)\n",
    "\n",
    "# Transform the entire city data to scaled values before prediction (using the same scaler)\n",
    "X_city_scaled = scaler.transform(X_city)\n",
    "\n",
    "# Predict growth for the entire city dataset\n",
    "opera['predicted_city_growth'] = lin_country.predict(X_city_scaled)\n",
    "\n",
    "# Sort cities based on predicted growth\n",
    "df_city_growth_sorted = opera[['iso', 'city', 'predicted_city_growth']].sort_values(by='predicted_city_growth', ascending=False)\n",
    "\n",
    "# Drop duplicates and keep the row with the highest growth for each city\n",
    "df_opera_city_growth_unique = df_city_growth_sorted.drop_duplicates(subset='city', keep='first')\n",
    "\n",
    "# Get top 25 cities with highest predicted growth\n",
    "top_cities_predicted = df_opera_city_growth_unique.head(10)\n",
    "print(top_cities_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9df4f37f-de92-47d0-8d7c-6a3b7af80920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 20.428280777427656\n",
      "MSE: 5380.81251451332\n",
      "RMSE: 73.35402180189796\n",
      "R2_Score: 0.0036593842846965874\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction\n",
    "y_pred_city_lin = lin_city.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate model\n",
    "lin_evaluate_model(y_test_city, y_pred_city_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077dd158-9c80-4238-9d4d-021df831b682",
   "metadata": {},
   "source": [
    "Linear Regression and grouping by sub-region for predictive analysis. This time I grouped the opera data by sub-regions before peforming the linear regression to see if it improved predictions.  The scores were significantly better for the cities prediction but they still were underperforming for the country data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "07535be7-df93-404a-b594-d67b6fd5a0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Country Name  predicted_country_growth\n",
      "12366       United States                384.528795\n",
      "16879          Kazakhstan                353.238890\n",
      "10028          Kyrgyzstan                325.570095\n",
      "32851          Uzbekistan                270.377483\n",
      "30634  Russian Federation                259.203609\n",
      "33363              Canada                248.547297\n",
      "17247              Poland                180.091249\n",
      "3100                Italy                 92.900284\n",
      "15701               Egypt                 90.607635\n",
      "3917              Romania                 77.953992\n"
     ]
    }
   ],
   "source": [
    "# Independent variables (predictors)\n",
    "X_country = opera[['country population', 'performances_season_by_country', 'perf_per_10k_ppl_co_pop',\n",
    "                   'city population', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', 'Year', 'Month', 'Day', \n",
    "                   'Weekday', 'Week_of_Year', 'Days_Since_Start']]\n",
    "\n",
    "# Dependent variable (growth at country level)\n",
    "y_country = opera['country_change_from_previous_season']\n",
    "\n",
    "# Group by Country\n",
    "country_groups = opera.groupby('sub-region')\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Model for country growth prediction\n",
    "lin_country = LinearRegression()\n",
    "\n",
    "# Store the predicted values in a DataFrame\n",
    "predicted_growth_values = pd.Series(index=opera.index)  # Create an empty Series to store predictions\n",
    "\n",
    "# Loop through each sub-region group to train and predict separately\n",
    "for country_name, group in country_groups:\n",
    "    # If the group has more than one sample, split and train\n",
    "    if len(group) > 1:\n",
    "        # Extract the features and target for this country group\n",
    "        X_group = group[['country population', 'performances_season_by_country', 'perf_per_10k_ppl_co_pop', \n",
    "                         'city population', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', 'Year', 'Month', 'Day', \n",
    "                         'Weekday', 'Week_of_Year', 'Days_Since_Start']]\n",
    "        y_group = group['country_change_from_previous_season']\n",
    "\n",
    "        # Split data into train and test sets (80% train, 20% test)\n",
    "        X_train, X_test, y_train_country, y_test_country = train_test_split(X_group, y_group, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Scale the training data\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "        # Train the model on the training data\n",
    "        lin_country.fit(X_train_scaled, y_train_country)\n",
    "\n",
    "        # Scale the test data using the same scaler\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # Make predictions for the test set\n",
    "        predictions = lin_country.predict(X_test_scaled)\n",
    "\n",
    "        # Assign predictions to the correct indices in the original DataFrame\n",
    "        predicted_growth_values.loc[X_test.index] = predictions  # Correctly assign predictions to test set rows\n",
    "    else:\n",
    "        # If the group has only one sample, predict directly and append\n",
    "        X_group = group[['country population', 'performances_season_by_country', 'perf_per_10k_ppl_co_pop', \n",
    "                         'city population', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', 'Year', 'Month', 'Day', \n",
    "                         'Weekday', 'Week_of_Year', 'Days_Since_Start']]\n",
    "        y_group = group['country_change_from_previous_season']\n",
    "        \n",
    "        # Scale the data for this group\n",
    "        X_scaled = scaler.fit_transform(X_group)\n",
    "\n",
    "        # Train the model\n",
    "        lin_country.fit(X_scaled, y_group)\n",
    "\n",
    "        # Make predictions for this group\n",
    "        predictions = lin_country.predict(X_scaled)\n",
    "        \n",
    "        # Assign predictions to the correct indices in the original DataFrame\n",
    "        predicted_growth_values.loc[group.index] = predictions  # Correctly assign predictions to the original rows\n",
    "\n",
    "# Assign the predicted values to the original DataFrame\n",
    "opera['predicted_country_growth'] = predicted_growth_values\n",
    "\n",
    "# Sort countries based on predicted growth\n",
    "df_country_growth_sorted = opera[['Country Name', 'predicted_country_growth']].sort_values(by='predicted_country_growth', ascending=False)\n",
    "\n",
    "# Drop duplicates and keep the row with the highest growth for each country\n",
    "df_opera_country_growth_unique = df_country_growth_sorted.drop_duplicates(subset='Country Name', keep='first')\n",
    "\n",
    "# Get top 10 countries with highest predicted growth\n",
    "top_countries_predicted = df_opera_country_growth_unique.head(10)\n",
    "print(top_countries_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "958e9637-d052-43af-a8b6-bcd08e1440ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 132.23534786689217\n",
      "MSE: 28676.095731319605\n",
      "RMSE: 169.34017754602598\n",
      "R2_Score: 0.042523402390002074\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction\n",
    "y_pred_country_lin = lin_country.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate model\n",
    "lin_evaluate_model(y_test_country, y_pred_country_lin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d23f7fad-c708-4366-a093-95340f84c61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      iso           city  predicted_city_growth\n",
      "15701  eg     Alexandria              71.954844\n",
      "30467  ru         Moscow              52.171187\n",
      "26239  us     Washington              51.766670\n",
      "10389  nz     Berhampore              42.547934\n",
      "13054  us    Saint Louis              41.165920\n",
      "11188  ru  St Petersburg              38.523518\n",
      "11980  us      Arlington              34.697543\n",
      "6536   am        Yerevan              34.630684\n",
      "12661  us        Madison              32.847327\n",
      "12412  us        Houston              32.374409\n"
     ]
    }
   ],
   "source": [
    "# Independent variables (predictors)\n",
    "X_city = opera[['country population', 'performances_season_by_country', 'perf_per_10k_ppl_co_pop',\n",
    "                   'city population', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', 'Year', 'Month', 'Day', \n",
    "                   'Weekday', 'Week_of_Year', 'Days_Since_Start']]\n",
    "\n",
    "# Dependent variable (growth at city level)\n",
    "y_city = opera['city_change_from_previous_season']\n",
    "\n",
    "# Still group the cities by Country\n",
    "city_groups = opera.groupby('sub-region')\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Model for country growth prediction\n",
    "lin_city = LinearRegression()\n",
    "\n",
    "# Store the predicted values in a DataFrame\n",
    "predicted_growth_values = pd.Series(index=opera.index)  # Create an empty Series to store predictions\n",
    "\n",
    "# Loop through each country group to train and predict separately\n",
    "for city_name, group in city_groups:\n",
    "    # If the group has more than one sample, split and train\n",
    "    if len(group) > 1:\n",
    "        # Extract the features and target for this country group\n",
    "        X_group = group[['country population', 'performances_season_by_country', 'perf_per_10k_ppl_co_pop', \n",
    "                         'city population', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', 'Year', 'Month', 'Day', \n",
    "                         'Weekday', 'Week_of_Year', 'Days_Since_Start']]\n",
    "        y_group = group['city_change_from_previous_season']\n",
    "\n",
    "        # Split data into train and test sets (80% train, 20% test)\n",
    "        X_train, X_test, y_train_city, y_test_city = train_test_split(X_group, y_group, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Scale the training data\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "        # Train the model on the training data\n",
    "        lin_city.fit(X_train_scaled, y_train_city)\n",
    "\n",
    "        # Scale the test data using the same scaler\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # Make predictions for the test set\n",
    "        predictions = lin_city.predict(X_test_scaled)\n",
    "\n",
    "        # Assign predictions to the correct indices in the original DataFrame\n",
    "        predicted_growth_values.loc[X_test.index] = predictions  # Correctly assign predictions to test set rows\n",
    "    else:\n",
    "        # If the group has only one sample, predict directly and append\n",
    "        X_group = group[['country population', 'performances_season_by_country', 'perf_per_10k_ppl_co_pop', \n",
    "                         'city population', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', 'Year', 'Month', 'Day', \n",
    "                         'Weekday', 'Week_of_Year', 'Days_Since_Start']]\n",
    "        y_group = group['city_change_from_previous_season']\n",
    "        \n",
    "        # Scale the data for this group\n",
    "        X_scaled = scaler.fit_transform(X_group)\n",
    "\n",
    "        # Train the model\n",
    "        lin_city.fit(X_scaled, y_group)\n",
    "\n",
    "        # Make predictions for this group\n",
    "        predictions = lin_city.predict(X_scaled)\n",
    "        \n",
    "        # Assign predictions to the correct indices in the original DataFrame\n",
    "        predicted_growth_values.loc[group.index] = predictions  # Correctly assign predictions to the original rows\n",
    "\n",
    "# Assign the predicted values to the original DataFrame\n",
    "opera['predicted_city_growth'] = predicted_growth_values\n",
    "\n",
    "# Sort countries based on predicted growth\n",
    "df_city_growth_sorted = opera[['iso', 'city', 'predicted_city_growth']].sort_values(by='predicted_city_growth', ascending=False)\n",
    "\n",
    "# Drop duplicates and keep the row with the highest growth for each country\n",
    "df_opera_city_growth_unique = df_city_growth_sorted.drop_duplicates(subset='city', keep='first')\n",
    "\n",
    "# Get top 10 countries with highest predicted growth\n",
    "top_cities_predicted = df_opera_city_growth_unique.head(10)\n",
    "print(top_cities_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f7673ad5-e24a-4277-a639-86068f1db99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 16.597406069575385\n",
      "MSE: 502.9302155600541\n",
      "RMSE: 22.426105670848294\n",
      "R2_Score: 0.011436314558350591\n"
     ]
    }
   ],
   "source": [
    "# Make a prediction\n",
    "y_pred_city_lin = lin_city.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate model\n",
    "lin_evaluate_model(y_test_city, y_pred_city_lin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abbe008-a80f-4c5b-afe4-6a8762e98a91",
   "metadata": {},
   "source": [
    "Logistic Regression Models - let's see if we can get a better predictive model using Logistic regression without countries being grouped first and then try it with grouping countries. In order to run a Logistic regression model, I binned the country_change_from_previous_season by quartiles into categories of Low, Medium, High and Very High so there is a category that is being used as the dependent outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e2120524-767c-4f77-8f52-e3af6cfe4227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "# Independent variables (predictors)\n",
    "X_country = opera[['country population', 'performances_season_by_country', 'perf_per_10k_ppl_co_pop',\n",
    "                   'city population', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', 'Year', 'Month', 'Day', \n",
    "                   'Weekday', 'Week_of_Year', 'Days_Since_Start']]\n",
    "\n",
    "# Dependent variable (growth at country level)\n",
    "y_country = opera['country_change_from_previous_season']\n",
    "\n",
    "# Convert continuous growth to categorical labels (Low, Medium, High)\n",
    "q1 = opera['country_change_from_previous_season'].quantile(0.25)\n",
    "q2 = opera['country_change_from_previous_season'].quantile(0.50)\n",
    "q3 = opera['country_change_from_previous_season'].quantile(0.75)\n",
    "\n",
    "bins = [-float('inf'), q1, q2, q3, float('inf')]\n",
    "labels = ['Low', 'Medium', 'High', 'Very High']\n",
    "\n",
    "y_country_classified = pd.cut(y_country, bins=bins, labels=labels)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train_country, y_test_country = train_test_split(X_country, y_country_classified, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data (using the same scaler as the training data)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4938c412-7640-4235-9b2f-4e2f094a126d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.1, 'solver': 'saga'}\n",
      "Best F1 Score: 0.4923619075830346\n"
     ]
    }
   ],
   "source": [
    "# Initialize LogisticRegression\n",
    "lr_country = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# Define the hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],  # Regularization strength\n",
    "    'solver': ['liblinear', 'saga'],  # Use 'liblinear' and 'saga' or 'lbfgs' for L1\n",
    "}\n",
    "\n",
    "# Define the custom scoring function (e.g., F1 score)\n",
    "custom_scorer = make_scorer(f1_score, average='weighted')\n",
    "\n",
    "# GridSearchCV with custom scoring\n",
    "grid_search = GridSearchCV(estimator=lr_country, param_grid=param_grid, scoring=custom_scorer, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train_country)\n",
    "\n",
    "# Output the best parameters and the best F1 score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best F1 Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "393ca4ca-eefb-4da8-9548-3b1f366fccb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Country Name predicted_country_growth\n",
      "14746             Germany                Very High\n",
      "4408   Russian Federation                Very High\n",
      "16534               Italy                Very High\n",
      "19042       United States                Very High\n",
      "35292              France                Very High\n",
      "11794      United Kingdom                   Medium\n",
      "10536              Poland                   Medium\n",
      "13624             Austria                   Medium\n",
      "10652             Romania                   Medium\n",
      "20573         Switzerland                   Medium\n"
     ]
    }
   ],
   "source": [
    "# Best parameters found during the grid search\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Create the Logistic Regression model with the best parameters\n",
    "lr_country = LogisticRegression(\n",
    "    C=best_params['C'],\n",
    "    solver=best_params['solver'],\n",
    "    max_iter=10000\n",
    ")\n",
    "\n",
    "# Train the model on scaled data\n",
    "lr_country.fit(X_train_scaled, y_train_country)\n",
    "\n",
    "# Transform the entire country data to scaled values before prediction (using the same scaler)\n",
    "X_country_scaled = scaler.transform(X_country)\n",
    "\n",
    "# Predict growth for the entire country dataset\n",
    "opera['predicted_country_growth'] = lr_country.predict(X_country_scaled)\n",
    "\n",
    "# Sort countries based on predicted growth\n",
    "df_country_growth_sorted = opera[['Country Name', 'predicted_country_growth']].sort_values(by='predicted_country_growth', ascending=False)\n",
    "\n",
    "# Drop duplicates and keep the row with the highest growth for each country\n",
    "df_opera_country_growth_unique = df_country_growth_sorted.drop_duplicates(subset='Country Name', keep='first')\n",
    "\n",
    "# Get top 10 countries with highest predicted growth\n",
    "top_countries_predicted = df_opera_country_growth_unique.head(10)\n",
    "print(top_countries_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b13aae30-1b4f-46d3-93a0-bda830abe562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5217000513610683\n",
      "Precision (macro): 0.4954212985332075\n",
      "Recall (macro): 0.519426396833789\n"
     ]
    }
   ],
   "source": [
    "#Make a prediction\n",
    "y_pred_country_lr = lr_country.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test_country, y_pred_country_lr)\n",
    "final_results.append(accuracy)\n",
    "evaluate_model(y_test_country, y_pred_country_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c8a9aa03-9849-4ac9-a3a4-794fa77ce5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent variables (predictors)\n",
    "X_country = opera[['country population', 'performances_season_by_country', 'perf_per_10k_ppl_co_pop',\n",
    "                   'city population', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', 'Year', 'Month', 'Day', \n",
    "                   'Weekday', 'Week_of_Year', 'Days_Since_Start']]\n",
    "\n",
    "# Dependent variable (growth at country level)\n",
    "y_country = opera['country_change_from_previous_season']\n",
    "\n",
    "# Convert continuous growth to categorical labels (Low, Medium, High)\n",
    "q1 = opera['country_change_from_previous_season'].quantile(0.25)\n",
    "q2 = opera['country_change_from_previous_season'].quantile(0.50)\n",
    "q3 = opera['country_change_from_previous_season'].quantile(0.75)\n",
    "\n",
    "bins = [-float('inf'), q1, q2, q3, float('inf')]\n",
    "labels = ['Low', 'Medium', 'High', 'Very High']\n",
    "\n",
    "y_country_classified = pd.cut(y_country, bins=bins, labels=labels)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train_country, y_test_country = train_test_split(X_country, y_country_classified, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data (using the same scaler as the training data)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e399022d-e0dc-47ca-a7e2-48909fe1a998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'solver': 'saga'}\n",
      "Best F1 Score: 0.48709776078392775\n"
     ]
    }
   ],
   "source": [
    "# Initialize LogisticRegression\n",
    "lr_country = LogisticRegression(max_iter=10000, multi_class='ovr')\n",
    "\n",
    "# Define the hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],  # Regularization strength\n",
    "    'solver': ['liblinear', 'saga'],  # Use 'liblinear' and 'saga' or 'lbfgs' for L1\n",
    "}\n",
    "\n",
    "# Define the custom scoring function (e.g., F1 score)\n",
    "custom_scorer = make_scorer(f1_score, average='weighted')\n",
    "\n",
    "# GridSearchCV with custom scoring\n",
    "grid_search = GridSearchCV(estimator=lr_country, param_grid=param_grid, scoring=custom_scorer, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train_country)\n",
    "\n",
    "# Output the best parameters and the best F1 score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best F1 Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5e8812b3-16fb-4201-be26-ccdbe5eeb4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v8/j1kjtws546j8drwljwyklgrm0000gn/T/ipykernel_6184/1954064732.py:49: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['Medium' 'High' 'High' 'High' 'High' 'High' 'High' 'High' 'Medium' 'High'\n",
      " 'High' 'Medium' 'High' 'High' 'High' 'Medium' 'High' 'High' 'High' 'High'\n",
      " 'High' 'High' 'High' 'High' 'High' 'High' 'High' 'High' 'Medium' 'High'\n",
      " 'High' 'High' 'High' 'High' 'High' 'Medium' 'High' 'High' 'High' 'High'\n",
      " 'High' 'High' 'High' 'High' 'High' 'High' 'High' 'High' 'High' 'Medium'\n",
      " 'High' 'High' 'High' 'High' 'High' 'High' 'High' 'Medium' 'High' 'High'\n",
      " 'High' 'High' 'Medium' 'High']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  predicted_growth_values.loc[X_test.index] = predictions  # Correctly assign predictions to test set rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping country: Northern Africa due to insufficient class variation in the target.\n",
      "Skipping country: South-eastern Asia due to insufficient class variation in the target.\n",
      "             Country Name predicted_country_growth\n",
      "14846             Germany                Very High\n",
      "13313       United States                Very High\n",
      "35890               Italy                Very High\n",
      "30564  Russian Federation                Very High\n",
      "11596      United Kingdom                Very High\n",
      "9024                Spain                Very High\n",
      "18084              Sweden                Very High\n",
      "35573             Hungary                   Medium\n",
      "27086      Czech Republic                   Medium\n",
      "15895              France                   Medium\n"
     ]
    }
   ],
   "source": [
    "# Best parameters found during the grid search\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Create the Logistic Regression model with the best parameters\n",
    "lr_country = LogisticRegression(\n",
    "    C=best_params['C'],\n",
    "    solver=best_params['solver'],\n",
    "    max_iter=10000,\n",
    "    multi_class='ovr'  # Specify multiclass handling (One-vs-Rest)\n",
    ")\n",
    "\n",
    "# Initialize a container to store predictions with correct dtype (categorical or object)\n",
    "predicted_growth_values = pd.Series(index=opera.index, dtype='object')\n",
    "\n",
    "# Group the data by 'Country Name'\n",
    "country_groups = opera.groupby('sub-region')\n",
    "\n",
    "# Loop through each country group to train and predict separately\n",
    "for country_name, group in country_groups:\n",
    "    # If the group has more than one sample and more than one class, split and train\n",
    "    if len(group) > 1 and len(group['country_change_from_previous_season'].unique()) > 1:\n",
    "        # Extract the features and target for this country group\n",
    "        X_group = group[['country population', 'performances_season_by_country', 'perf_per_10k_ppl_co_pop', \n",
    "                         'city population', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', 'Year', 'Month', 'Day', \n",
    "                         'Weekday', 'Week_of_Year', 'Days_Since_Start']]\n",
    "        y_group = group['country_change_from_previous_season']\n",
    "\n",
    "        # Convert the target to categorical labels (same as before)\n",
    "        y_group_classified = pd.cut(y_group, bins=bins, labels=labels)\n",
    "\n",
    "        # Split data into train and test sets (80% train, 20% test)\n",
    "        X_train, X_test, y_train_country, y_test_country = train_test_split(X_group, y_group_classified, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Scale the training data\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "        # **Only train if the target variable has more than one class**\n",
    "        if len(y_train_country.unique()) > 1:\n",
    "            # Train the model on the training data\n",
    "            lr_country.fit(X_train_scaled, y_train_country)\n",
    "\n",
    "            # Scale the test data using the same scaler\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "            # Make predictions for the test set\n",
    "            predictions = lr_country.predict(X_test_scaled)\n",
    "\n",
    "            # Assign predictions to the correct indices in the original DataFrame\n",
    "            predicted_growth_values.loc[X_test.index] = predictions  # Correctly assign predictions to test set rows\n",
    "        else:\n",
    "            print(f\"Skipping country: {country_name} due to insufficient class variation in the target.\")\n",
    "            continue\n",
    "    else:\n",
    "        # Skip the group if it has only one class or one sample\n",
    "        print(f\"Skipping country: {country_name} due to insufficient class variation or sample size.\")\n",
    "        continue\n",
    "\n",
    "# You can now inspect or save the results\n",
    "opera['predicted_country_growth'] = predicted_growth_values\n",
    "\n",
    "# Sort and get the top countries based on predicted growth\n",
    "df_country_growth_sorted = opera[['Country Name', 'predicted_country_growth']].sort_values(by='predicted_country_growth', ascending=False)\n",
    "\n",
    "# Drop duplicates and keep the row with the highest growth for each country\n",
    "df_opera_country_growth_unique = df_country_growth_sorted.drop_duplicates(subset='Country Name', keep='first')\n",
    "\n",
    "# Get top 10 countries with highest predicted growth\n",
    "top_countries_predicted = df_opera_country_growth_unique.head(10)\n",
    "print(top_countries_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "84012119-4125-4c3b-a6f2-9736880b3113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6017592962814874\n",
      "Precision (macro): 0.6043315110531736\n",
      "Recall (macro): 0.6110848694378016\n"
     ]
    }
   ],
   "source": [
    "#Make a prediction\n",
    "y_pred_country_lr = lr_country.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test_country, y_pred_country_lr)\n",
    "final_results.append(accuracy)\n",
    "evaluate_model(y_test_country, y_pred_country_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5001e3ba-3289-47b7-b002-c8d70e31c10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent variables (predictors)\n",
    "X_city = opera[['country population', 'performances_season_by_country', 'perf_per_10k_ppl_co_pop',\n",
    "                   'city population', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', 'Year', 'Month', 'Day', \n",
    "                   'Weekday', 'Week_of_Year', 'Days_Since_Start']]\n",
    "\n",
    "# Dependent variable (growth at city level)\n",
    "y_city = opera['city_change_from_previous_season']\n",
    "\n",
    "# Convert continuous growth to categorical labels (Low, Medium, High)\n",
    "q1 = opera['city_change_from_previous_season'].quantile(0.25)\n",
    "q2 = opera['city_change_from_previous_season'].quantile(0.50)\n",
    "q3 = opera['city_change_from_previous_season'].quantile(0.75)\n",
    "\n",
    "bins = [-float('inf'), q1, q2, q3, float('inf')]\n",
    "labels = ['Low', 'Medium', 'High', 'Very High']\n",
    "\n",
    "y_city_classified = pd.cut(y_city, bins=bins, labels=labels)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train_city, y_test_city = train_test_split(X_city, y_city_classified, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data (using the same scaler as the training data)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7c56e026-de24-46b0-899f-c6950b4c0cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.1, 'solver': 'saga'}\n",
      "Best F1 Score: 0.32796112406192546\n"
     ]
    }
   ],
   "source": [
    "# Initialize LogisticRegression\n",
    "lr_city = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# Define the hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],  # Regularization strength\n",
    "    'solver': ['liblinear', 'saga'],  # Use 'liblinear' and 'saga' or 'lbfgs' for L1\n",
    "}\n",
    "\n",
    "# Define the custom scoring function (e.g., F1 score)\n",
    "custom_scorer = make_scorer(f1_score, average='weighted')\n",
    "\n",
    "# GridSearchCV with custom scoring\n",
    "grid_search = GridSearchCV(estimator=lr_city, param_grid=param_grid, scoring=custom_scorer, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train_city)\n",
    "\n",
    "# Output the best parameters and the best F1 score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best F1 Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "88985dcc-badc-4536-91ed-6054364e5956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      iso          city predicted_city_growth\n",
      "19469  us      New York             Very High\n",
      "31379  uk        London             Very High\n",
      "14771  de     Frankfurt             Very High\n",
      "14754  de         Essen             Very High\n",
      "31548  us     Arlington             Very High\n",
      "14879  de         Hagen             Very High\n",
      "14914  de       Hamburg             Very High\n",
      "14472  de        Berlin             Very High\n",
      "14528  de  Braunschweig             Very High\n",
      "14534  de        Bremen             Very High\n"
     ]
    }
   ],
   "source": [
    "# Best parameters found during the grid search\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Create the Logistic Regression model with the best parameters\n",
    "lr_city = LogisticRegression(\n",
    "    C=best_params['C'],\n",
    "    solver=best_params['solver'],\n",
    "    max_iter=10000\n",
    ")\n",
    "\n",
    "# Train the model on scaled data\n",
    "lr_city.fit(X_train_scaled, y_train_city)\n",
    "\n",
    "# Transform the entire city data to scaled values before prediction (using the same scaler)\n",
    "X_city_scaled = scaler.transform(X_city)\n",
    "\n",
    "# Predict growth for the entire city dataset\n",
    "opera['predicted_city_growth'] = lr_city.predict(X_city_scaled)\n",
    "\n",
    "# Sort countries based on predicted growth\n",
    "df_city_growth_sorted = opera[['iso', 'city', 'predicted_city_growth']].sort_values(by='predicted_city_growth', ascending=False)\n",
    "\n",
    "# Drop duplicates and keep the row with the highest growth for each city\n",
    "df_opera_city_growth_unique = df_city_growth_sorted.drop_duplicates(subset='city', keep='first')\n",
    "\n",
    "# Get top 10 cities with highest predicted growth\n",
    "top_cities_predicted = df_opera_city_growth_unique.head(10)\n",
    "print(top_cities_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3a2e0846-6bc7-4087-9cc8-e635a1f4a163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.34232152028762197\n",
      "Precision (macro): 0.3622382334573313\n",
      "Recall (macro): 0.33420688494479084\n"
     ]
    }
   ],
   "source": [
    "#Make a prediction\n",
    "y_pred_city_lr = lr_city.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test_city, y_pred_city_lr)\n",
    "final_results.append(accuracy)\n",
    "evaluate_model(y_test_city, y_pred_city_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a09eb9eb-6714-4cbd-a9a5-72320addde97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent variables (predictors)\n",
    "X_city = opera[['country population', 'performances_season_by_country', 'perf_per_10k_ppl_co_pop',\n",
    "                   'city population', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', 'Year', 'Month', 'Day', \n",
    "                   'Weekday', 'Week_of_Year', 'Days_Since_Start']]\n",
    "\n",
    "# Dependent variable (growth at city level)\n",
    "y_city = opera['city_change_from_previous_season']\n",
    "\n",
    "# Convert continuous growth to categorical labels (Low, Medium, High)\n",
    "q1 = opera['city_change_from_previous_season'].quantile(0.25)\n",
    "q2 = opera['city_change_from_previous_season'].quantile(0.50)\n",
    "q3 = opera['city_change_from_previous_season'].quantile(0.75)\n",
    "\n",
    "bins = [-float('inf'), q1, q2, q3, float('inf')]\n",
    "labels = ['Low', 'Medium', 'High', 'Very High']\n",
    "\n",
    "y_city_classified = pd.cut(y_city, bins=bins, labels=labels)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train_city, y_test_city = train_test_split(X_city, y_city_classified, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data (using the same scaler as the training data)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1620ddbd-9aee-49ff-9263-735bda0fc075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'solver': 'liblinear'}\n",
      "Best F1 Score: 0.3248013022646522\n"
     ]
    }
   ],
   "source": [
    "# Initialize LogisticRegression\n",
    "lr_city = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# Define the hyperparameter grid for tuning\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],  # Regularization strength\n",
    "    'solver': ['liblinear', 'saga'],  # Use 'liblinear' and 'saga' or 'lbfgs' for L1\n",
    "}\n",
    "\n",
    "# Define the custom scoring function (e.g., F1 score)\n",
    "custom_scorer = make_scorer(f1_score, average='weighted')\n",
    "\n",
    "# GridSearchCV with custom scoring\n",
    "grid_search = GridSearchCV(estimator=lr_city, param_grid=param_grid, scoring=custom_scorer, cv=5)\n",
    "grid_search.fit(X_train_scaled, y_train_city)\n",
    "\n",
    "# Output the best parameters and the best F1 score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best F1 Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "aedc5821-74c8-40bc-8138-726abc2231d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      iso          city predicted_city_growth\n",
      "38935  uz      Tashkent             Very High\n",
      "32944  at          Graz             Very High\n",
      "33004  at      Salzburg             Very High\n",
      "32984  at          Linz             Very High\n",
      "32959  at     Innsbruck             Very High\n",
      "13343  us    Washington             Very High\n",
      "32898  ar  Buenos Aires             Very High\n",
      "32868  za     Cape Town             Very High\n",
      "32839  us    Wilmington             Very High\n",
      "33126  au     Melbourne             Very High\n"
     ]
    }
   ],
   "source": [
    "# Best parameters found during the grid search\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Create the Logistic Regression model with the best parameters\n",
    "lr_city = LogisticRegression(\n",
    "    C=best_params['C'],\n",
    "    solver=best_params['solver'],\n",
    "    max_iter=10000,\n",
    "    multi_class='ovr'  # Specify multiclass handling (One-vs-Rest)\n",
    ")\n",
    "\n",
    "# Initialize a container to store predictions with correct dtype (categorical or object)\n",
    "predicted_growth_values = pd.Series(index=opera.index, dtype='object')\n",
    "\n",
    "# Still group the data by 'sub-region'\n",
    "city_groups = opera.groupby('sub-region')\n",
    "\n",
    "# Loop through each sub-region group to train and predict separately for cities\n",
    "for city_name, group in city_groups:\n",
    "    # If the group has more than one sample and more than one class, split and train\n",
    "    if len(group) > 1 and len(group['city_change_from_previous_season'].unique()) > 1:\n",
    "        # Extract the features and target for this sub-region group\n",
    "        X_group = group[['country population', 'performances_season_by_country', 'perf_per_10k_ppl_co_pop', \n",
    "                         'city population', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', 'Year', 'Month', 'Day', \n",
    "                         'Weekday', 'Week_of_Year', 'Days_Since_Start']]\n",
    "        y_group = group['city_change_from_previous_season']\n",
    "\n",
    "        # Convert the target to categorical labels (same as before)\n",
    "        y_group_classified = pd.cut(y_group, bins=bins, labels=labels)\n",
    "\n",
    "        # Split data into train and test sets (80% train, 20% test)\n",
    "        X_train, X_test, y_train_city, y_test_city = train_test_split(X_group, y_group_classified, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Scale the training data\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "        # **Only train if the target variable has more than one class**\n",
    "        if len(y_train_city.unique()) > 1:\n",
    "            # Train the model on the training data\n",
    "            lr_city.fit(X_train_scaled, y_train_city)\n",
    "\n",
    "            # Scale the test data using the same scaler\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "            # Make predictions for the test set\n",
    "            predictions = lr_city.predict(X_test_scaled)\n",
    "\n",
    "            # Ensure the indices of predictions and X_test match\n",
    "            predicted_growth_values.loc[X_test.index] = predictions  # Correctly assign predictions to test set rows\n",
    "        else:\n",
    "            print(f\"Skipping sub-region: {city_name} due to insufficient class variation in the target.\")\n",
    "            continue\n",
    "    else:\n",
    "        # Skip the group if it has only one class or one sample\n",
    "        print(f\"Skipping sub-region: {city_name} due to insufficient class variation or sample size.\")\n",
    "        continue\n",
    "\n",
    "# You can now inspect or save the results\n",
    "opera['predicted_city_growth'] = predicted_growth_values\n",
    "\n",
    "# Sort and get the top cities based on predicted growth\n",
    "df_city_growth_sorted = opera[['iso', 'city', 'predicted_city_growth']].sort_values(by='predicted_city_growth', ascending=False)\n",
    "\n",
    "# Drop duplicates and keep the row with the highest growth for each city\n",
    "df_opera_city_growth_unique = df_city_growth_sorted.drop_duplicates(subset='city', keep='first')\n",
    "\n",
    "# Get top 10 cities with highest predicted growth\n",
    "top_cities_predicted = df_opera_city_growth_unique.head(10)\n",
    "print(top_cities_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "257fefb0-50f9-40fd-9507-0c40e136c17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3790483806477409\n",
      "Precision (macro): 0.4056179485771411\n",
      "Recall (macro): 0.37454003271170466\n"
     ]
    }
   ],
   "source": [
    "#Make a prediction\n",
    "y_pred_city_lr = lr_city.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test_city, y_pred_city_lr)\n",
    "final_results.append(accuracy)\n",
    "evaluate_model(y_test_city, y_pred_city_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c8ea47-0a5f-4bf6-9fcd-60fbe54f5629",
   "metadata": {},
   "source": [
    "Random Forest Classifier since the models for countries and cities were not very strong with logistic regression and might work better with RCF since it's a stronger model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1d6451-90b0-419e-bf92-704c9a5a1e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Independent variables (predictors)\n",
    "X_country = opera[['country population', 'performances_season_by_country', 'perf_per_10k_ppl_co_pop',\n",
    "                 'city population', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', \n",
    "                 'Year', 'Month', 'Day', 'Weekday', 'Week_of_Year', 'Days_Since_Start']]\n",
    "\n",
    "# Dependent variable (growth at city level)\n",
    "y_country = opera['city_change_from_previous_season']\n",
    "\n",
    "# Convert continuous growth to categorical labels (Low, Medium, High)\n",
    "q1 = opera['city_change_from_previous_season'].quantile(0.25)\n",
    "q2 = opera['city_change_from_previous_season'].quantile(0.50)\n",
    "q3 = opera['city_change_from_previous_season'].quantile(0.75)\n",
    "\n",
    "bins = [-float('inf'), q1, q2, q3, float('inf')]\n",
    "labels = ['Low', 'Medium', 'High', 'Very High']\n",
    "\n",
    "y_city_classified = pd.cut(y_city, bins=bins, labels=labels)\n",
    "\n",
    "# Train-test split (80% train, 20% test)\n",
    "X_train, X_test, y_train_city, y_test_city = train_test_split(X_city, y_city_classified, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data (using the same scaler as the training data)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ada48c3-f655-443e-b52f-db2674fbcf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid for GridSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': np.arange(100, 1001, 100),  # 100, 200, ..., 1000\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],  # Added this line\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Initialize RandomForestClassifier\n",
    "rf_city = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Define a custom scoring function (e.g., F1 score)\n",
    "custom_scorer = make_scorer(f1_score, average='weighted')\n",
    "\n",
    "# GridSearchCV initialization with custom scoring\n",
    "grid_search = GridSearchCV(estimator=rf_city, \n",
    "                           param_grid=param_dist, \n",
    "                           cv=5,  # Number of folds in cross-validation\n",
    "                           n_jobs=-1,  # Use all CPU cores\n",
    "                           verbose=2,  # Print progress messages\n",
    "                           scoring=custom_scorer)  # Use F1 score for evaluation\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train_scaled, y_train_city)\n",
    "\n",
    "# Output the best parameters and the best F1 score\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best F1 Score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaa15b7-0e41-4a9f-bea5-fe870b4fd81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a container to store predictions with correct dtype (categorical or object)\n",
    "predicted_growth_values = pd.Series(index=opera.index, dtype='object')\n",
    "\n",
    "# Still group the data by 'sub-region'\n",
    "city_groups = opera.groupby('sub-region')\n",
    "\n",
    "# Loop through each country group to train and predict separately for cities\n",
    "for city_name, group in city_groups:\n",
    "    # If the group has more than one sample and more than one class, split and train\n",
    "    if len(group) > 1 and len(group['city_change_from_previous_season'].unique()) > 1:\n",
    "        # Extract the features and target for this country group\n",
    "        X_group = group[['country population', 'performances_season_by_country', 'perf_per_10k_ppl_co_pop', \n",
    "                         'city population', 'performances_season_by_city', 'perf_per_1k_ppl_city_pop', 'Year', 'Month', 'Day', \n",
    "                         'Weekday', 'Week_of_Year', 'Days_Since_Start']]\n",
    "        y_group = group['city_change_from_previous_season']\n",
    "\n",
    "        # Convert the target to categorical labels (same as before)\n",
    "        y_group_classified = pd.cut(y_group, bins=bins, labels=labels)\n",
    "\n",
    "        # Split data into train and test sets (80% train, 20% test)\n",
    "        X_train, X_test, y_train_city, y_test_city = train_test_split(X_group, y_group_classified, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Scale the training data\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "        # **Only train if the target variable has more than one class**\n",
    "        if len(y_train_city.unique()) > 1:\n",
    "            # Train the Random Forest Classifier\n",
    "            rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "            rf_classifier.fit(X_train_scaled, y_train_city)\n",
    "\n",
    "            # Scale the test data using the same scaler\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "            # Make predictions for the test set\n",
    "            predictions = rf_classifier.predict(X_test_scaled)\n",
    "\n",
    "            # Assign predictions to the correct indices in the original DataFrame\n",
    "            predicted_growth_values.loc[X_test.index] = predictions  # Correctly assign predictions to test set rows\n",
    "        else:\n",
    "            print(f\"Skipping city: {city_name} due to insufficient class variation in the target.\")\n",
    "            continue\n",
    "    else:\n",
    "        # Skip the group if it has only one class or one sample\n",
    "        print(f\"Skipping city: {city_name} due to insufficient class variation or sample size.\")\n",
    "        continue\n",
    "\n",
    "# You can now inspect or save the results\n",
    "opera['predicted_city_growth'] = predicted_growth_values\n",
    "df_city_growth_sorted = opera[['iso', 'city', 'predicted_city_growth']].sort_values(by='predicted_city_growth', ascending=False)\n",
    "\n",
    "# Drop duplicates and keep the row with the highest growth for each city\n",
    "df_opera_city_growth_unique = df_city_growth_sorted.drop_duplicates(subset='city', keep='first')\n",
    "\n",
    "# Get top 10 cities with highest predicted growth\n",
    "top_cities_predicted = df_opera_city_growth_unique.head(10)\n",
    "print(top_cities_predicted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
